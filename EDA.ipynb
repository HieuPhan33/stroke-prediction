{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "import math\n",
    "import re\n",
    "from sklearn.pipeline import make_pipeline,Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from spellchecker import SpellChecker\n",
    "from word2number import w2n\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_number(s):\n",
    "    \"\"\" Returns True is string is a number. \"\"\"\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  (34872, 14)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "print(\"Training \",train.shape)\n",
    "test = pd.read_csv('data/test.csv')\n",
    "train[\"stroke_in_2018\"]=train[\"stroke_in_2018\"].apply(lambda x: x if x in [\"0\",\"1\"] else None)\n",
    "y_train = train[\"stroke_in_2018\"]\n",
    "spell = SpellChecker()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Duplicate data in train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(grp):\n",
    "    df = pd.DataFrame()\n",
    "    if(grp.shape[0] > 1):\n",
    "        for c in grp.columns:\n",
    "            value_counts = grp[c].value_counts().index.astype(grp[c].dtypes)\n",
    "            if value_counts.size > 1:\n",
    "                print(grp, value_counts) #Error\n",
    "            elif value_counts.size == 1:\n",
    "                df[c] = value_counts[0]\n",
    "            else:\n",
    "                df[c] = None\n",
    "    else:\n",
    "        df = grp.head(1)\n",
    "    return df\n",
    "train = train.groupby(\"id\").apply(merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_data size is : (43342, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Program\\Anaconda\\envs\\NLP\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "ntrain = y_train.shape[0]\n",
    "all_data = pd.concat((train, test)).reset_index(drop=True)\n",
    "all_data.drop(['stroke_in_2018'], axis=1, inplace=True)\n",
    "print(\"all_data size is : {}\".format(all_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34872\n"
     ]
    }
   ],
   "source": [
    "print(ntrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_job_status_and_living_area_reversed(x):\n",
    "    return ((x[\"job_status\"] != None and x[\"job_status\"] in (\"r\", \"c\", \"city\", \"remote\", \"remotee\"))\n",
    "             or (x[\"living_area\"] != None and x[\"living_area\"] in (\"private_sector\", \"business_owner\")))\n",
    "def process_job_status(x):\n",
    "    if x == None or x in (\"nan\", 'null', \"\", 'n.a'):\n",
    "        return None\n",
    "    elif x in (\"private sector\", \"privattte\", \"private\", \"private_sector\"):\n",
    "        return \"private_sector\"\n",
    "    elif x in (\"government\", \"govt.\"):\n",
    "        return \"government\"\n",
    "    elif x in (\"business_owner\", \"business owner\", \"biz\"):\n",
    "        return \"business_owner\"\n",
    "    elif x in (\"parental_leave\", \"parental leave\"):\n",
    "        return \"parental_leave\"\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "def process_living_area(x):\n",
    "    if x == None or x in (\"nan\", 'null', \"\", 'n.a'):\n",
    "        return None\n",
    "    elif x == 'c':\n",
    "        return 'city'\n",
    "    elif x in ('r', 'remotee'):\n",
    "        return 'remote'\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "def split_job_status_and_living_area(x):\n",
    "    pair = x.lower().split(\"?\") if x != None else [x, x]\n",
    "    if len(pair) < 2:\n",
    "        pair = [pair[0], None]\n",
    "    return pair\n",
    "\n",
    "def process_job_status_and_living_area(df):\n",
    "    df[\"job_status\"] = df[\"job_status and living_area\"].astype(str).apply(split_job_status_and_living_area).apply(lambda x: x[0])\n",
    "    df[\"living_area\"] = df[\"job_status and living_area\"].astype(str).apply(split_job_status_and_living_area).apply(lambda x: x[1])\n",
    "    job_status = df.apply(lambda x: x[\"living_area\"] if is_job_status_and_living_area_reversed(x) else x[\"job_status\"], 1)\n",
    "    living_area = df.apply(lambda x: x[\"job_status\"] if is_job_status_and_living_area_reversed(x) else x[\"living_area\"], 1)\n",
    "    df[\"job_status\"] = job_status.apply(lambda x: process_job_status(x))\n",
    "    df[\"living_area\"] = living_area.apply(lambda x: process_living_area(x))\n",
    "    df.drop(columns='job_status and living_area',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_job_status_and_living_area(all_data)\n",
    "#process_job_status_and_living_area(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_smoker_status(x):\n",
    "    if x == None:\n",
    "        return None\n",
    "    elif x.startswith(\"non\"):\n",
    "        return \"non-smoker\"\n",
    "    elif x.startswith(\"quit\"):\n",
    "        return \"quit\"\n",
    "    elif x.startswith(\"active\"):\n",
    "        return \"active_smoker\"\n",
    "    else:\n",
    "        return None\n",
    "all_data[\"smoker_status\"] = all_data[\"smoker_status\"].astype(str).apply(process_smoker_status)\n",
    "#test[\"smoker_status\"] = test[\"smoker_status\"].astype(str).apply(process_smoker_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_binary_col(df,columns):\n",
    "    for col in columns:\n",
    "        df[col] = pd.to_numeric(df[col],errors=\"coerce\")\n",
    "        df[col] = df[col].astype(int,errors='ignore')\n",
    "        df[col] = df[col].apply(lambda x: x if x in [0,1] else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_binary_col(all_data,[\"heart_condition_detected_2017\",\"high_BP\",\"married\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert BMI to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"BMI\"] = pd.to_numeric(all_data[\"BMI\"],errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process gender into oneof \"F\", \"M\" and \"OTHER\"\n",
    "def genderSpellingRewrite(gender_str):\n",
    "    if not isinstance(gender_str, str):\n",
    "        return None;\n",
    "    uppered = gender_str.upper()\n",
    "    # Repeated single occurence should be truncate.\n",
    "    patternM = re.compile('[M]+$')\n",
    "    if (patternM.match(uppered)):\n",
    "        return \"M\"\n",
    "    patternF = re.compile('[F]+$')\n",
    "    if (patternF.match(uppered)):\n",
    "        return \"F\"\n",
    "    # Misspelling should be corrected and replaced.\n",
    "    # TODO: Malle is not going to be corrected as Male.Need to update spell's known list.\n",
    "    corrected = spell.correction(uppered).upper()\n",
    "    if (corrected == \"FEMALE\"):\n",
    "        return \"F\"\n",
    "    if (corrected == \"MALE\"):\n",
    "        return \"M\"\n",
    "    if (corrected == \"OTHER\"):\n",
    "        return \"OTHER\"\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process human number word into number\n",
    "def numberConversion(potential_number_word):\n",
    "    # Correct any possible miss spelled number_word\n",
    "    corrected_potential_word = spell.correction(potential_number_word)\n",
    "    # check it it means number\n",
    "    try:\n",
    "      potential_num = w2n.word_to_num(corrected_potential_word)\n",
    "    except ValueError:\n",
    "        return potential_number_word\n",
    "    return potential_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatSexAge(origin_str):\n",
    "    if not isinstance(origin_str, str):\n",
    "        return [None,None]\n",
    "    # Preprocess \n",
    "    # Entry with missing column.\n",
    "    if (',' not in origin_str):\n",
    "        origin_str = origin_str + ',';\n",
    "    origin_list = origin_str.replace(\" \", \"\").upper().split(\",\")\n",
    "    if(origin_list[0].upper() == \"NAN\"):\n",
    "        origin_list[0] = \"\"\n",
    "    if(origin_list[1].upper() == \"NAN\"):\n",
    "        origin_list[1] = \"\"\n",
    "    # Convert possible number in entry.\n",
    "    if((not is_number(origin_list[0])) and (not is_number(origin_list[1]))):\n",
    "        origin_list[0] = numberConversion(origin_list[0])\n",
    "        origin_list[1] = numberConversion(origin_list[1])\n",
    "    genderSet = set(['F', 'M', 'OTHER'])\n",
    "    if (is_number(origin_list[0])):\n",
    "        # wrong entry (num, num)\n",
    "        if (is_number(origin_list[1])):\n",
    "            if (origin_list[0] == origin_list[1]):\n",
    "                return [None, origin_list[0]]\n",
    "            return [None, None]\n",
    "        else: # first number, second '' or gender (NOT num for sure)\n",
    "          # swap back number\n",
    "          origin_list = origin_list[::-1]\n",
    "          origin_list[0] = genderSpellingRewrite(origin_list[0])\n",
    "          return origin_list\n",
    "    else: \n",
    "        origin_list[0] = genderSpellingRewrite(origin_list[0])\n",
    "         # first '' or str, second is number\n",
    "        if (is_number(origin_list[1])):\n",
    "            return origin_list\n",
    "        else:\n",
    "            origin_list[1] = genderSpellingRewrite(origin_list[1])\n",
    "            if(origin_list[0] == origin_list[1]):\n",
    "               origin_list[1] = None\n",
    "            return origin_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BMI',\n",
       " 'TreatmentA',\n",
       " 'TreatmentB',\n",
       " 'TreatmentC',\n",
       " 'TreatmentD',\n",
       " 'average_blood_sugar',\n",
       " 'heart_condition_detected_2017',\n",
       " 'high_BP',\n",
       " 'id',\n",
       " 'married',\n",
       " 'sex and age',\n",
       " 'smoker_status',\n",
       " 'job_status',\n",
       " 'living_area']"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sex_age_(df):\n",
    "    df[\"sex_age_list\"] = df[\"sex and age\"].astype(str).apply(lambda x: formatSexAge(x))\n",
    "    df[['sex','age']] = pd.DataFrame(df[\"sex_age_list\"].values.tolist(), index= df.index)\n",
    "    df[df[\"sex\"] == \"None\"][\"sex\"] = \"OTHER\"\n",
    "process_sex_age_(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Sex and Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_sex_age(sex_age_list):\n",
    "#     if type(sex_age_list) is not list:\n",
    "#         return [None,None]\n",
    "#     # Strip and Upper case both sex and age\n",
    "#     sex_age_list[0],sex_age_list[1] = sex_age_list[0].strip().upper(), sex_age_list[1].strip().upper()\n",
    "    \n",
    "#     # 2nd : first one is empty and second one is not numeric\n",
    "#     if (is_number(sex_age_list[0]) or (not sex_age_list[0] and not is_number(sex_age_list[1]))): \n",
    "#         sex_age_list = sex_age_list[::-1]\n",
    "#     sex = sex_age_list[0].strip().upper()\n",
    "    \n",
    "#     if sex in ('FEMALE','FEMALLE'):\n",
    "#         sex = 'F'\n",
    "#     if sex in ('MALE','MMALE','MM'):\n",
    "#         sex = 'M'\n",
    "\n",
    "#     sex_age_list[0] = sex\n",
    "#     sex_age_list[1] = sex_age_list[1]\n",
    "#     return sex_age_list\n",
    "\n",
    "# def process_sex_age(df):\n",
    "#     df[\"sex_age_list\"] = df[\"sex and age\"].str.split(\",\").apply(clean_sex_age)\n",
    "#     df[['sex','age']] = pd.DataFrame(df[\"sex_age_list\"].values.tolist(), index= df.index)\n",
    "#     df[\"age\"] = pd.to_numeric(df[\"age\"],errors='coerce').round()\n",
    "#     return df.drop(columns=[\"sex_age_list\",\"sex and age\"])\n",
    "# all_data = process_sex_age(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"age\"] = pd.to_numeric(all_data[\"age\"],errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(df):\n",
    "    return df[:ntrain], df[ntrain:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_train, preprocessed_test = split_train_test(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_categorical(df, columns):\n",
    "    for col in columns:\n",
    "        df[col] = df[col].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_by_mode(df,columns):\n",
    "    for col in columns:\n",
    "        df[col] = df[col].fillna(df[col].mode().iloc[0])\n",
    "def impute_by_median(df,columns):\n",
    "    for col in columns:\n",
    "        df[col] = df[col].fillna(df[col].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_by_mode(all_data,[\"heart_condition_detected_2017\",\"high_BP\",\"married\",\"job_status\"])\n",
    "impute_by_median(all_data,[\"average_blood_sugar\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"sex\"] = all_data[\"sex\"].fillna(\"OTHER\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute Age by Median group by sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = preprocessed_train.groupby(\"sex\")[\"age\"].median().reset_index(name=\"MedianAge\")\n",
    "df_merge = all_data.merge(df_tmp,on=\"sex\",how=\"left\")\n",
    "cond = df_merge['age'].isnull()\n",
    "df_merge['age'] = df_merge['age'].fillna(df_merge[\"MedianAge\"])\n",
    "all_data = df_merge.drop(columns=\"MedianAge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check missing value of smoker_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_categorical(all_data,[\"heart_condition_detected_2017\",\"married\",\"high_BP\",\"job_status\",\n",
    "                                 \"sex\",\"living_area\"])\n",
    "preprocessed_train, preprocessed_test = split_train_test(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_missing(df,missing_var,independent_var,model):\n",
    "    selected_cols = independent_var+[missing_var]\n",
    "    non_missing_data = df[df[missing_var].notnull()][selected_cols]\n",
    "    # Remove missing values\n",
    "    non_missing_data = non_missing_data.dropna()\n",
    "    print(\"Training data for missing value \",non_missing_data.shape)\n",
    "    \n",
    "    # Build Random Forest classifier\n",
    "    clf = make_pipeline(OneHotEncoder(handle_unknown=\"ignore\"),model)\n",
    "    clf.fit(non_missing_data[independent_var],non_missing_data[missing_var])\n",
    "    acc = np.mean(cross_val_score(clf,non_missing_data[independent_var],non_missing_data[missing_var],cv=5))\n",
    "    print(\"Random Forest Mean Accuracy for 5 runs of cross validation \", acc)\n",
    "    \n",
    "    # Predict missing values\n",
    "    cond = df[missing_var].isnull()\n",
    "    df[cond][missing_var] = clf.predict(df[cond][independent_var])\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data for missing value  (30057, 7)\n",
      "Random Forest Mean Accuracy for 5 runs of cross validation  0.5330871339239283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Program\\Anaconda\\envs\\NLP\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "clf = predict_missing(all_data,\"smoker_status\",[\"age\",\"sex\",\"married\",\"high_BP\",\"living_area\",\"average_blood_sugar\"],\n",
    "                        RandomForestClassifier(n_estimators=600, max_depth=7))\n",
    "# clf = rf_predict_missing(all_data,\"\",[\"BMI\",\"age\",\"sex\",\"high_BP\",\"married\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impute_by_median(all_data,[\"BMI\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data for missing value  (41862, 8)\n",
      "Random Forest Mean Accuracy for 5 runs of cross validation  0.37993869711196276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Program\\Anaconda\\envs\\NLP\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('onehotencoder', OneHotEncoder(categorical_features=None, categories=None,\n",
       "       dtype=<class 'numpy.float64'>, handle_unknown='ignore',\n",
       "       n_values=None, sparse=True)), ('adaboostclassifier', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None))])"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bmi_category(bmi):\n",
    "    if pd.isnull(bmi):\n",
    "        return np.nan\n",
    "    if bmi > 35:\n",
    "        return \"SO\"\n",
    "    elif bmi > 30:\n",
    "        return \"MO\"\n",
    "    elif bmi > 25:\n",
    "        return \"O\"\n",
    "    elif bmi > 18.5:\n",
    "        return \"N\"\n",
    "    else:\n",
    "        return \"U\"\n",
    "\n",
    "all_data[\"bmi_category\"] = all_data[\"BMI\"].apply(bmi_category)\n",
    "predict_missing(all_data,\"bmi_category\", [\"job_status\", \"high_BP\", \"heart_condition_detected_2017\",\n",
    "                                             \"married\", \"age\", \"sex\", \"average_blood_sugar\"],AdaBoostClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_vars = [\"sex\",\"age\",\"high_BP\",\"heart_condition_detected_2017\",\n",
    "                \"married\",\"job_status\",\"living_area\",\"average_blood_sugar\",\n",
    "                \"bmi_category\",\"smoker_status\"]\n",
    "selected_data = all_data[selected_vars]\n",
    "selected_data = pd.get_dummies(selected_data).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data  (34872, 27)  target  (34872,)\n",
      "Testing data (8470, 27)\n"
     ]
    }
   ],
   "source": [
    "X_train = selected_data[:ntrain]\n",
    "X_test = selected_data[ntrain:]\n",
    "print(\"Training data \",X_train.shape, \" target \",y_train.shape)\n",
    "print(\"Testing data\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore Data Complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-548-cb67ffe6d6bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtransformer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKernelPCA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rbf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprojected\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mfinalDf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mprojected\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program\\Anaconda\\envs\\NLP\\lib\\site-packages\\sklearn\\decomposition\\kernel_pca.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    274\u001b[0m         \u001b[0mX_new\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlike\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m         \"\"\"\n\u001b[1;32m--> 276\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[0mX_transformed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malphas_\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlambdas_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program\\Anaconda\\envs\\NLP\\lib\\site-packages\\sklearn\\decomposition\\kernel_pca.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_centerer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKernelCenterer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m         \u001b[0mK\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_kernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 253\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_inverse_transform\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program\\Anaconda\\envs\\NLP\\lib\\site-packages\\sklearn\\decomposition\\kernel_pca.py\u001b[0m in \u001b[0;36m_fit_transform\u001b[1;34m(self, K)\u001b[0m\n\u001b[0;32m    182\u001b[0m         \u001b[1;34m\"\"\" Fit's using kernel K\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m         \u001b[1;31m# center kernel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m         \u001b[0mK\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_centerer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_components\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program\\Anaconda\\envs\\NLP\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    460\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program\\Anaconda\\envs\\NLP\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, K, y, copy)\u001b[0m\n\u001b[0;32m   1905\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'K_fit_all_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1906\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1907\u001b[1;33m         \u001b[0mK\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1909\u001b[0m         K_pred_cols = (np.sum(K, axis=1) /\n",
      "\u001b[1;32mE:\\Program\\Anaconda\\envs\\NLP\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmay_share_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marray_orig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m         \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    599\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m     if (warn_on_dtype and dtypes_orig is not None and\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "transformer = KernelPCA(n_components=2, kernel='rbf') \n",
    "projected = transformer.fit_transform(X_train)\n",
    "finalDf = pd.concat([projected, y_train], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = fig.add_subplot(1,1,1) \n",
    "ax.set_xlabel('Principal Component 1', fontsize = 15)\n",
    "ax.set_ylabel('Principal Component 2', fontsize = 15)\n",
    "ax.set_title('2 component PCA', fontsize = 20)\n",
    "targets = [0,1]\n",
    "colors = ['r', 'g']\n",
    "for target, color in zip(targets,colors):\n",
    "    indicesToKeep = finalDf[''] == target\n",
    "    ax.scatter(finalDf.loc[indicesToKeep, 'principal component 1']\n",
    "               , finalDf.loc[indicesToKeep, 'principal component 2']\n",
    "               , c = color\n",
    "               , s = 50)\n",
    "ax.legend(targets)\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_var = \"smoker_status\"\n",
    "independent_var = [\"BMI\",\"age\",\"sex\",\"married\",\"high_BP\",\"living_area\"]\n",
    "non_missing_data = preprocessed_train[preprocessed_train[missing_var].notnull()][independent_var+[missing_var]]\n",
    "# print(non_missing_data.notnull())\n",
    "non_missing_data[non_missing_data.isnull().any(axis=1)]\n",
    "non_missing_data.dropna(inplace=True)\n",
    "non_missing_data[non_missing_data.isna().any(axis=1)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Program\\Anaconda\\envs\\NLP\\lib\\site-packages\\pandas\\core\\frame.py:3781: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  return super(DataFrame, self).rename(**kwargs)\n",
      "E:\\Program\\Anaconda\\envs\\NLP\\lib\\site-packages\\pandas\\core\\internals.py:389: FutureWarning: in the future negative indices will not be ignored by `numpy.delete`.\n",
      "  self.values = np.delete(self.values, loc, 0)\n",
      "E:\\Program\\Anaconda\\envs\\NLP\\lib\\site-packages\\pandas\\core\\internals.py:390: FutureWarning: in the future negative indices will not be ignored by `numpy.delete`.\n",
      "  self.mgr_locs = self.mgr_locs.delete(loc)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Gaps in blk ref_locs",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-544-6ddada9ece18>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprofile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofile_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Medical Record Profiling Report'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprofile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"train_data_summary.html\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program\\Anaconda\\envs\\NLP\\lib\\site-packages\\pandas_profiling\\controller\\pandas_decorator.py\u001b[0m in \u001b[0;36mprofile_report\u001b[1;34m(df, **kwargs)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mProfileReport\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \"\"\"\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mProfileReport\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program\\Anaconda\\envs\\NLP\\lib\\site-packages\\pandas_profiling\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, df, **kwargs)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[1;31m# Get dataset statistics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m         \u001b[0mdescription_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdescribe_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;31m# Get sample\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program\\Anaconda\\envs\\NLP\\lib\\site-packages\\pandas_profiling\\model\\describe.py\u001b[0m in \u001b[0;36mdescribe\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m     \u001b[1;31m# Get correlations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 464\u001b[1;33m     \u001b[0mcorrelations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalculate_correlations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    465\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m     \u001b[1;31m# Check correlations between numerical variables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program\\Anaconda\\envs\\NLP\\lib\\site-packages\\pandas_profiling\\model\\correlations.py\u001b[0m in \u001b[0;36mcalculate_correlations\u001b[1;34m(df, variables)\u001b[0m\n\u001b[0;32m    142\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"correlations\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcorrelation_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m                 \u001b[0mcorrelation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorrelation_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorrelation\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m                     \u001b[0mcorrelations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcorrelation_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcorrelation\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program\\Anaconda\\envs\\NLP\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mcorr\u001b[1;34m(self, method, min_periods)\u001b[0m\n\u001b[0;32m   6499\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6500\u001b[0m         \"\"\"\n\u001b[1;32m-> 6501\u001b[1;33m         \u001b[0mnumeric_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_numeric_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6502\u001b[0m         \u001b[0mcols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumeric_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6503\u001b[0m         \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program\\Anaconda\\envs\\NLP\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_numeric_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   4508\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_numeric_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4509\u001b[0m         return self._constructor(\n\u001b[1;32m-> 4510\u001b[1;33m             self._data.get_numeric_data()).__finalize__(self)\n\u001b[0m\u001b[0;32m   4511\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4512\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_bool_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program\\Anaconda\\envs\\NLP\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget_numeric_data\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m   3842\u001b[0m             \u001b[0mWhether\u001b[0m \u001b[0mto\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mblocks\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3843\u001b[0m         \"\"\"\n\u001b[1;32m-> 3844\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3845\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcombine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mb\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_numeric\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3846\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program\\Anaconda\\envs\\NLP\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   4104\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_consolidated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4105\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_known_consolidated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4106\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rebuild_blknos_and_blklocs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4108\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program\\Anaconda\\envs\\NLP\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36m_rebuild_blknos_and_blklocs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3377\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnew_blknos\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3378\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Gaps in blk ref_locs\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3379\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3380\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_blknos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_blknos\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Gaps in blk ref_locs"
     ]
    }
   ],
   "source": [
    "profile = X_train.profile_report(title='Medical Record Profiling Report')\n",
    "profile.to_file(output_file=\"train_data_summary.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
