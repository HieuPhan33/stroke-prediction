{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "import math\n",
    "import re\n",
    "import sklearn\n",
    "from sklearn.pipeline import make_pipeline,Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from spellchecker import SpellChecker\n",
    "from word2number import w2n\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "sns.set_style('darkgrid')\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_number(s):\n",
    "    \"\"\" Returns True is string is a number. \"\"\"\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "train[\"stroke_in_2018\"]=train[\"stroke_in_2018\"].apply(lambda x: x if x in [\"0\",\"1\"] else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8718, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Duplicate data in train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(grp):\n",
    "    df = pd.DataFrame()\n",
    "    if(grp.shape[0] > 1):\n",
    "        for c in grp.columns:\n",
    "            value_counts = grp[c].value_counts().index.astype(grp[c].dtypes)\n",
    "            if value_counts.size > 1:\n",
    "                print(grp, value_counts) #Error\n",
    "            elif value_counts.size == 1:\n",
    "                df[c] = value_counts[0]\n",
    "            else:\n",
    "                df[c] = None\n",
    "    else:\n",
    "        df = grp.head(1)\n",
    "    return df\n",
    "train = train.groupby(\"id\").apply(merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  (34595, 14)\n"
     ]
    }
   ],
   "source": [
    "train = train[pd.notnull(train['stroke_in_2018'])] # Remove if target is NULL\n",
    "y_train = train[\"stroke_in_2018\"]\n",
    "print(\"Training \",train.shape)\n",
    "spell = SpellChecker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_data size is : (43313, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Program\\Anaconda\\envs\\PythonGPU\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "ntrain = y_train.shape[0]\n",
    "all_data = pd.concat((train, test)).reset_index(drop=True)\n",
    "all_data.drop(['stroke_in_2018'], axis=1, inplace=True)\n",
    "print(\"all_data size is : {}\".format(all_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_job_status_and_living_area_reversed(x):\n",
    "    return ((x[\"job_status\"] != None and x[\"job_status\"] in (\"r\", \"c\", \"city\", \"remote\", \"remotee\"))\n",
    "             or (x[\"living_area\"] != None and x[\"living_area\"] in (\"private_sector\", \"business_owner\")))\n",
    "def process_job_status(x):\n",
    "    if x == None or x in (\"nan\", 'null', \"\", 'n.a'):\n",
    "        return None\n",
    "    elif x in (\"private sector\", \"privattte\", \"private\", \"private_sector\"):\n",
    "        return \"private_sector\"\n",
    "    elif x in (\"government\", \"govt.\"):\n",
    "        return \"government\"\n",
    "    elif x in (\"business_owner\", \"business owner\", \"biz\"):\n",
    "        return \"business_owner\"\n",
    "    elif x in (\"parental_leave\", \"parental leave\"):\n",
    "        return \"parental_leave\"\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "def process_living_area(x):\n",
    "    if x == None or x in (\"nan\", 'null', \"\", 'n.a'):\n",
    "        return None\n",
    "    elif x == 'c':\n",
    "        return 'city'\n",
    "    elif x in ('r', 'remotee'):\n",
    "        return 'remote'\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "def split_job_status_and_living_area(x):\n",
    "    pair = x.lower().split(\"?\") if x != None else [x, x]\n",
    "    if len(pair) < 2:\n",
    "        pair = [pair[0], None]\n",
    "    return pair\n",
    "\n",
    "def process_job_status_and_living_area(df):\n",
    "    df[\"job_status\"] = df[\"job_status and living_area\"].astype(str).apply(split_job_status_and_living_area).apply(lambda x: x[0])\n",
    "    df[\"living_area\"] = df[\"job_status and living_area\"].astype(str).apply(split_job_status_and_living_area).apply(lambda x: x[1])\n",
    "    job_status = df.apply(lambda x: x[\"living_area\"] if is_job_status_and_living_area_reversed(x) else x[\"job_status\"], 1)\n",
    "    living_area = df.apply(lambda x: x[\"job_status\"] if is_job_status_and_living_area_reversed(x) else x[\"living_area\"], 1)\n",
    "    df[\"job_status\"] = job_status.apply(lambda x: process_job_status(x))\n",
    "    df[\"living_area\"] = living_area.apply(lambda x: process_living_area(x))\n",
    "    df.drop(columns='job_status and living_area',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_job_status_and_living_area(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_smoker_status(x):\n",
    "    if x == None:\n",
    "        return None\n",
    "    elif x.startswith(\"non\"):\n",
    "        return \"non-smoker\"\n",
    "    elif x.startswith(\"quit\"):\n",
    "        return \"quit\"\n",
    "    elif x.startswith(\"active\"):\n",
    "        return \"active_smoker\"\n",
    "    else:\n",
    "        return None\n",
    "all_data[\"smoker_status\"] = all_data[\"smoker_status\"].astype(str).apply(process_smoker_status)\n",
    "#test[\"smoker_status\"] = test[\"smoker_status\"].astype(str).apply(process_smoker_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_binary_col(df,columns):\n",
    "    for col in columns:\n",
    "        df[col] = pd.to_numeric(df[col],errors=\"coerce\")\n",
    "        df[col] = df[col].astype(int,errors='ignore')\n",
    "        df[col] = df[col].apply(lambda x: x if x in [0,1] else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_binary_col(all_data,[\"heart_condition_detected_2017\",\"high_BP\",\"married\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert BMI to numeric\n",
    "all_data[\"BMI\"] = pd.to_numeric(all_data[\"BMI\"],errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process gender into oneof \"F\", \"M\" and \"OTHER\"\n",
    "def genderSpellingRewrite(gender_str):\n",
    "    if not isinstance(gender_str, str):\n",
    "        return None;\n",
    "    uppered = gender_str.upper()\n",
    "    # Repeated single occurence should be truncate.\n",
    "    patternM = re.compile('[M]+$')\n",
    "    if (patternM.match(uppered)):\n",
    "        return \"M\"\n",
    "    patternF = re.compile('[F]+$')\n",
    "    if (patternF.match(uppered)):\n",
    "        return \"F\"\n",
    "    # Misspelling should be corrected and replaced.\n",
    "    # TODO: Malle is not going to be corrected as Male.Need to update spell's known list.\n",
    "    corrected = spell.correction(uppered).upper()\n",
    "    if (corrected == \"FEMALE\"):\n",
    "        return \"F\"\n",
    "    if (corrected == \"MALE\"):\n",
    "        return \"M\"\n",
    "    if (corrected == \"OTHER\"):\n",
    "        return \"OTHER\"\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process human number word into number\n",
    "def numberConversion(potential_number_word):\n",
    "    # Correct any possible miss spelled number_word\n",
    "    corrected_potential_word = spell.correction(potential_number_word)\n",
    "    # check it it means number\n",
    "    try:\n",
    "      potential_num = w2n.word_to_num(corrected_potential_word)\n",
    "    except ValueError:\n",
    "        return potential_number_word\n",
    "    return potential_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatSexAge(origin_str):\n",
    "    if not isinstance(origin_str, str):\n",
    "        return [None,None]\n",
    "    # Preprocess \n",
    "    # Entry with missing column.\n",
    "    if (',' not in origin_str):\n",
    "        origin_str = origin_str + ',';\n",
    "    origin_list = origin_str.replace(\" \", \"\").upper().split(\",\")\n",
    "    if(origin_list[0].upper() == \"NAN\"):\n",
    "        origin_list[0] = \"\"\n",
    "    if(origin_list[1].upper() == \"NAN\"):\n",
    "        origin_list[1] = \"\"\n",
    "    # Convert possible number in entry.\n",
    "    if((not is_number(origin_list[0])) and (not is_number(origin_list[1]))):\n",
    "        origin_list[0] = numberConversion(origin_list[0])\n",
    "        origin_list[1] = numberConversion(origin_list[1])\n",
    "    genderSet = set(['F', 'M', 'OTHER'])\n",
    "    if (is_number(origin_list[0])):\n",
    "        # wrong entry (num, num)\n",
    "        if (is_number(origin_list[1])):\n",
    "            if (origin_list[0] == origin_list[1]):\n",
    "                return [None, origin_list[0]]\n",
    "            return [None, None]\n",
    "        else: # first number, second '' or gender (NOT num for sure)\n",
    "          # swap back number\n",
    "          origin_list = origin_list[::-1]\n",
    "          origin_list[0] = genderSpellingRewrite(origin_list[0])\n",
    "          return origin_list\n",
    "    else: \n",
    "        origin_list[0] = genderSpellingRewrite(origin_list[0])\n",
    "         # first '' or str, second is number\n",
    "        if (is_number(origin_list[1])):\n",
    "            return origin_list\n",
    "        else:\n",
    "            origin_list[1] = genderSpellingRewrite(origin_list[1])\n",
    "            if(origin_list[0] == origin_list[1]):\n",
    "               origin_list[1] = None\n",
    "            return origin_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sex_age_(df):\n",
    "    df[\"sex_age_list\"] = df[\"sex and age\"].astype(str).apply(lambda x: formatSexAge(x))\n",
    "    df[['sex','age']] = pd.DataFrame(df[\"sex_age_list\"].values.tolist(), index= df.index)\n",
    "    df[df[\"sex\"] == \"None\"][\"sex\"] = \"OTHER\"\n",
    "process_sex_age_(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Sex and Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"age\"] = pd.to_numeric(all_data[\"age\"],errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(df):\n",
    "    print(\"Train shape \",df[:ntrain].shape)\n",
    "    print(\"Test shape \",df[ntrain:].shape)\n",
    "    return df[:ntrain], df[ntrain:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape  (34595, 17)\n",
      "Test shape  (8718, 17)\n"
     ]
    }
   ],
   "source": [
    "preprocessed_train, preprocessed_test = split_train_test(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_categorical(df, columns):\n",
    "    for col in columns:\n",
    "        df[col] = df[col].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation of Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_by_mode(df,columns):\n",
    "    for col in columns:\n",
    "        df[col] = df[col].fillna(df[col].mode().iloc[0])\n",
    "def impute_by_median(df,columns):\n",
    "    for col in columns:\n",
    "        df[col] = df[col].fillna(df[col].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_by_mode(all_data,[\"heart_condition_detected_2017\",\"high_BP\",\"married\",\"job_status\"])\n",
    "impute_by_median(all_data,[\"average_blood_sugar\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"sex\"] = all_data[\"sex\"].fillna(\"OTHER\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute Age by Median group by sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = preprocessed_train.groupby(\"sex\")[\"age\"].median().reset_index(name=\"MedianAge\")\n",
    "df_merge = all_data.merge(df_tmp,on=\"sex\",how=\"left\")\n",
    "cond = df_merge['age'].isnull()\n",
    "df_merge['age'] = df_merge['age'].fillna(df_merge[\"MedianAge\"])\n",
    "all_data = df_merge.drop(columns=\"MedianAge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape  (34595, 17)\n",
      "Test shape  (8718, 17)\n"
     ]
    }
   ],
   "source": [
    "convert_to_categorical(all_data,[\"heart_condition_detected_2017\",\"married\",\"high_BP\",\"job_status\",\n",
    "                                 \"sex\",\"living_area\"])\n",
    "preprocessed_train, preprocessed_test = split_train_test(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_missing(df,missing_var,independent_var,model):\n",
    "    selected_cols = independent_var+[missing_var]\n",
    "    non_missing_data = df[df[missing_var].notnull()][selected_cols]\n",
    "    # Remove missing values\n",
    "    non_missing_data = non_missing_data.dropna()\n",
    "    print(\"Training data for missing value \",non_missing_data.shape)\n",
    "    \n",
    "    # Build Random Forest classifier\n",
    "    clf = make_pipeline(OneHotEncoder(handle_unknown=\"ignore\"),model)\n",
    "    clf.fit(non_missing_data[independent_var],non_missing_data[missing_var])\n",
    "    acc = np.mean(cross_val_score(clf,non_missing_data[independent_var],non_missing_data[missing_var],cv=5))\n",
    "    print(\"Random Forest Mean Accuracy for 5 runs of cross validation \", acc)\n",
    "    \n",
    "    # Predict missing values\n",
    "    cond = df[missing_var].isnull()\n",
    "    df[cond][missing_var] = clf.predict(df[cond][independent_var])\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data for missing value  (30045, 7)\n",
      "Random Forest Mean Accuracy for 5 runs of cross validation  0.5331336398924217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Program\\Anaconda\\envs\\PythonGPU\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "clf = predict_missing(all_data,\"smoker_status\",[\"age\",\"sex\",\"married\",\"high_BP\",\"living_area\",\"average_blood_sugar\"],\n",
    "                        RandomForestClassifier(n_estimators=600, max_depth=7))\n",
    "# clf = rf_predict_missing(all_data,\"\",[\"BMI\",\"age\",\"sex\",\"high_BP\",\"married\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data for missing value  (41847, 8)\n",
      "Random Forest Mean Accuracy for 5 runs of cross validation  0.3800028581800948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Program\\Anaconda\\envs\\PythonGPU\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('onehotencoder',\n",
       "                 OneHotEncoder(categorical_features=None, categories=None,\n",
       "                               drop=None, dtype=<class 'numpy.float64'>,\n",
       "                               handle_unknown='ignore', n_values=None,\n",
       "                               sparse=True)),\n",
       "                ('adaboostclassifier',\n",
       "                 AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "                                    learning_rate=1.0, n_estimators=50,\n",
       "                                    random_state=None))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bmi_category(bmi):\n",
    "    if pd.isnull(bmi):\n",
    "        return np.nan\n",
    "    if bmi > 35:\n",
    "        return \"SO\"\n",
    "    elif bmi > 30:\n",
    "        return \"MO\"\n",
    "    elif bmi > 25:\n",
    "        return \"O\"\n",
    "    elif bmi > 18.5:\n",
    "        return \"N\"\n",
    "    else:\n",
    "        return \"U\"\n",
    "\n",
    "all_data[\"bmi_category\"] = all_data[\"BMI\"].apply(bmi_category)\n",
    "predict_missing(all_data,\"bmi_category\", [\"job_status\", \"high_BP\", \"heart_condition_detected_2017\",\n",
    "                                             \"married\", \"age\", \"sex\", \"average_blood_sugar\"],AdaBoostClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_missing(all_data,\"BMI\", [\"job_status\", \"high_BP\", \"heart_condition_detected_2017\",\n",
    "                                             \"married\", \"age\", \"sex\", \"average_blood_sugar\"],\n",
    "                ElasticNet(random_state=0,max_iter=3000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_vars = [\"sex\",\"age\",\"high_BP\",\"heart_condition_detected_2017\",\n",
    "                \"married\",\"job_status\",\"living_area\",\"average_blood_sugar\",\n",
    "                \"bmi_category\",\"smoker_status\"]\n",
    "selected_data = all_data[selected_vars]\n",
    "selected_data_ohe = pd.get_dummies(selected_data).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-702ad4212e57>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mX_train_ohe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselected_data_ohe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mntrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mX_test_ohe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselected_data_ohe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mntrain\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Training data \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\" target \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Testing data\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "X_train_ohe = selected_data_ohe[:ntrain]\n",
    "X_test_ohe = selected_data_ohe[ntrain:]\n",
    "print(\"Training data \",X_train_ohe.shape, \" target \",y_train.shape)\n",
    "print(\"Testing data\", X_test_ohe.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = selected_data[:ntrain]\n",
    "X_test = selected_data[ntrain:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore Data Complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot2D(X,y):\n",
    "    df_tsne = pd.DataFrame()\n",
    "    df_tsne['stroke'] = y\n",
    "    tsne = TSNE(n_components=2, verbose=1, perplexity=50, n_iter=3000)\n",
    "    tsne_results = tsne.fit_transform(X)\n",
    "    df_tsne['tsne_v1'] = tsne_results[:,0]\n",
    "    df_tsne['tsne_v2'] = tsne_results[:,1]\n",
    "    # Make the plot\n",
    "    sns.scatterplot(\n",
    "        x=\"tsne_v1\", y=\"tsne_v2\",\n",
    "        hue=\"stroke\",\n",
    "        palette=sns.hls_palette(2, l=.3, s=.9),\n",
    "        data=df_tsne,\n",
    "        legend=\"full\",\n",
    "        alpha=0.3\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tsne = TSNE(n_components=2, verbose=1, perplexity=50, n_iter=3000)\n",
    "# tsne_results = tsne.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = all_data.profile_report(title='Medical Record Profiling Report')\n",
    "profile.to_file(output_file=\"train_data_summary.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from imblearn.ensemble import RUSBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.under_sampling import ClusterCentroids,InstanceHardnessThreshold\n",
    "#plot_2d_space(X_cc, y_cc, 'Cluster Centroids under-sampling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-104305952f37>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munder_sampling\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTomekLinks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTomekLinks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreturn_indices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mratio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'majority'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mX_tl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_tl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import TomekLinks\n",
    "tl = TomekLinks(return_indices=False, ratio='majority')\n",
    "X_tl, y_tl = tl.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot2D(X_cc,y_cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfolds = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "def grid_search(X_train,y_train,model,param_grid,scoring=[\"f1\",\"roc_auc\"],refit=\"roc_auc\"):\n",
    "    gs = GridSearchCV(model,param_grid=param_grid,scoring=scoring,refit=refit,cv=kfolds)\n",
    "    gs.fit(X_train,y_train)\n",
    "    results = gs.cv_results_\n",
    "    print(refit,\" =\",gs.best_score_,\" achieved by configuration : \",gs.best_params_)\n",
    "    best_idx = np.argwhere(results['rank_test_%s' % refit] == 1)[0,0]\n",
    "    for scorer in scoring:\n",
    "        for sample in ['test']:\n",
    "            sample_score_mean = results['mean_%s_%s' % (sample, scorer)][best_idx]\n",
    "            print(sample,\"_\",scorer,\":\",sample_score_mean)\n",
    "    return gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = ClusterCentroids(ratio={\"0\": 4000})\n",
    "X_cc, y_cc = cc.fit_sample(X_train_ohe, y_train)\n",
    "y_cc = y_cc.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_model(X,y,model,params):\n",
    "#     cc = ClusterCentroids(ratio={\"0\": 1500})\n",
    "#     X_cc, y_cc = cc.fit_sample(X, y)\n",
    "#     y_cc = y_cc.astype(int)\n",
    "#     return grid_search(X_cc,y_cc,model,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = Pipeline([\n",
    "        ('rs',RobustScaler()),\n",
    "        ('svm',SVC(random_state=0,class_weight=\"balanced\",gamma='auto'))\n",
    "    ])\n",
    "params = {\"svm__kernel\":[\"linear\",\"rbf\"],\"svm__C\":np.logspace(-5, 1, num=10, base=2)}\n",
    "gs_svm = grid_search(X_cc,y_cc,svm,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = gs_svm.cv_results_\n",
    "test_score = cvres[\"mean_test_score\"]\n",
    "train_score = cvres[\"mean_train_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "lg = lgb.LGBMClassifier(silent=False)\n",
    "param_dist = {\"max_depth\": [2,3,4,5,6,7,8,9,10,15],\n",
    "              \"learning_rate\" : [0.1,0.15,0.2,0.25,0.3,0.4],\n",
    "              \"num_leaves\": [20,30,40,60,80,100,120],\n",
    "              \"n_estimators\": [200]\n",
    "             }\n",
    "gs_lightboost = grid_search(X_cc,y_cc,lg,param_dist)\n",
    "#train_model(X_train_ohe,y_train,lg,param_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUSBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RUSBoostClassifier(n_estimators = 50)\n",
    "best_ensemble = grid_search(X_train_ohe, y_train, model, param_grid = {\n",
    "    \"base_estimator\" : [\n",
    "        lgb.LGBMClassifier(silent=False,n_estimators=50,num_leaves=20,learning_rate=0.2,max_depth=5)\n",
    "        BaggingClassifier(),\n",
    "        AdaBoostClassifier(), ExtraTreesClassifier(),GradientBoostingClassifier(),\n",
    "        GradientBoostingClassifier(loss = \"exponential\"),RandomForestClassifier(),\n",
    "    ],\n",
    "    \"learning_rate\":np.linspace(1e-2,1,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = gs_lightboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = SVC(random_state=0,kernel='rbf',class_weight=\"balanced\",gamma='auto',C=0.19842513149602492)\n",
    "final_model.fit(X_cc,y_cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = final_model.predict(X_test_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit = pd.DataFrame()\n",
    "df_submit[\"id\"] = test[\"id\"]\n",
    "df_submit[\"stroke_in_2018\"] = pd.Series(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit.to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit[\"stroke_in_2018\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = gs_svm.cv_results_\n",
    "test_score = cvres[\"mean_test_score\"]\n",
    "train_score = cvres[\"mean_train_score\"]\n",
    "plt.plot(alpha,test_score,label=\"test_score\")\n",
    "plt.plot(alpha,train_score,label=\"train_score\")\n",
    "plt.legend()\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('r2 score')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
