{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "import math\n",
    "import re\n",
    "from sklearn.pipeline import make_pipeline,Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from spellchecker import SpellChecker\n",
    "from word2number import w2n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_number(s):\n",
    "    \"\"\" Returns True is string is a number. \"\"\"\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "spell = SpellChecker()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Duplicate data in train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(grp):\n",
    "    df = pd.DataFrame()\n",
    "    if(grp.shape[0] > 1):\n",
    "        for c in grp.columns:\n",
    "            value_counts = grp[c].value_counts().index.astype(grp[c].dtypes)\n",
    "            if value_counts.size > 1:\n",
    "                print(grp, value_counts) #Error\n",
    "            elif value_counts.size == 1:\n",
    "                df[c] = value_counts[0]\n",
    "            else:\n",
    "                df[c] = None\n",
    "    else:\n",
    "        df = grp.head(1)\n",
    "    return df\n",
    "train = train.groupby(\"id\").apply(merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_data size is : (43342, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "ntrain = train.shape[0]\n",
    "ntest = train.shape[0]\n",
    "all_data = pd.concat((train, test)).reset_index(drop=True)\n",
    "all_data.drop(['stroke_in_2018'], axis=1, inplace=True)\n",
    "print(\"all_data size is : {}\".format(all_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_job_status_and_living_area_reversed(x):\n",
    "    return ((x[\"job_status\"] != None and x[\"job_status\"] in (\"r\", \"c\", \"city\", \"remote\", \"remotee\"))\n",
    "             or (x[\"living_area\"] != None and x[\"living_area\"] in (\"private_sector\", \"business_owner\")))\n",
    "def process_job_status(x):\n",
    "    if x == None or x in (\"nan\", 'null', \"\", 'n.a'):\n",
    "        return None\n",
    "    elif x in (\"private sector\", \"privattte\", \"private\", \"private_sector\"):\n",
    "        return \"private_sector\"\n",
    "    elif x in (\"government\", \"govt.\"):\n",
    "        return \"government\"\n",
    "    elif x in (\"business_owner\", \"business owner\", \"biz\"):\n",
    "        return \"business_owner\"\n",
    "    elif x in (\"parental_leave\", \"parental leave\"):\n",
    "        return \"parental_leave\"\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "def process_living_area(x):\n",
    "    if x == None or x in (\"nan\", 'null', \"\", 'n.a'):\n",
    "        return None\n",
    "    elif x == 'c':\n",
    "        return 'city'\n",
    "    elif x in ('r', 'remotee'):\n",
    "        return 'remote'\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "def split_job_status_and_living_area(x):\n",
    "    pair = x.lower().split(\"?\") if x != None else [x, x]\n",
    "    if len(pair) < 2:\n",
    "        pair = [pair[0], None]\n",
    "    return pair\n",
    "\n",
    "def process_job_status_and_living_area(df):\n",
    "    df[\"job_status\"] = df[\"job_status and living_area\"].astype(str).apply(split_job_status_and_living_area).apply(lambda x: x[0])\n",
    "    df[\"living_area\"] = df[\"job_status and living_area\"].astype(str).apply(split_job_status_and_living_area).apply(lambda x: x[1])\n",
    "    job_status = df.apply(lambda x: x[\"living_area\"] if is_job_status_and_living_area_reversed(x) else x[\"job_status\"], 1)\n",
    "    living_area = df.apply(lambda x: x[\"job_status\"] if is_job_status_and_living_area_reversed(x) else x[\"living_area\"], 1)\n",
    "    df[\"job_status\"] = job_status.apply(lambda x: process_job_status(x))\n",
    "    df[\"living_area\"] = living_area.apply(lambda x: process_living_area(x))\n",
    "    df.drop(columns='job_status and living_area',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_job_status_and_living_area(all_data)\n",
    "#process_job_status_and_living_area(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_smoker_status(x):\n",
    "    if x == None:\n",
    "        return None\n",
    "    elif x.startswith(\"non\"):\n",
    "        return \"non-smoker\"\n",
    "    elif x.startswith(\"quit\"):\n",
    "        return \"quit\"\n",
    "    elif x.startswith(\"active\"):\n",
    "        return \"active_smoker\"\n",
    "    else:\n",
    "        return None\n",
    "all_data[\"smoker_status\"] = all_data[\"smoker_status\"].astype(str).apply(process_smoker_status)\n",
    "#test[\"smoker_status\"] = test[\"smoker_status\"].astype(str).apply(process_smoker_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_binary_col(df,columns):\n",
    "    for col in columns:\n",
    "        df[col] = pd.to_numeric(df[col],errors=\"coerce\")\n",
    "        df[col] = df[col].astype(int,errors='ignore')\n",
    "        df[col] = df[col].apply(lambda x: x if x in [0,1] else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_binary_col(all_data,[\"heart_condition_detected_2017\",\"high_BP\",\"married\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert BMI to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"BMI\"] = pd.to_numeric(all_data[\"BMI\"],errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process gender into oneof \"F\", \"M\" and \"OTHER\"\n",
    "def genderSpellingRewrite(gender_str):\n",
    "    if not isinstance(gender_str, str):\n",
    "        return None;\n",
    "    uppered = gender_str.upper()\n",
    "    # Repeated single occurence should be truncate.\n",
    "    patternM = re.compile('[M]+$')\n",
    "    if (patternM.match(uppered)):\n",
    "        return \"M\"\n",
    "    patternF = re.compile('[F]+$')\n",
    "    if (patternF.match(uppered)):\n",
    "        return \"F\"\n",
    "    # Misspelling should be corrected and replaced.\n",
    "    # TODO: Malle is not going to be corrected as Male.Need to update spell's known list.\n",
    "    corrected = spell.correction(uppered).upper()\n",
    "    if (corrected == \"FEMALE\"):\n",
    "        return \"F\"\n",
    "    if (corrected == \"MALE\"):\n",
    "        return \"M\"\n",
    "    if (corrected == \"OTHER\"):\n",
    "        return \"OTHER\"\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process human number word into number\n",
    "def numberConversion(potential_number_word):\n",
    "    # Correct any possible miss spelled number_word\n",
    "    corrected_potential_word = spell.correction(potential_number_word)\n",
    "    # check it it means number\n",
    "    try:\n",
    "      potential_num = w2n.word_to_num(corrected_potential_word)\n",
    "    except ValueError:\n",
    "        return potential_number_word\n",
    "    return potential_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatSexAge(origin_str):\n",
    "    if not isinstance(origin_str, str):\n",
    "        return [None,None]\n",
    "    # Preprocess \n",
    "    # Entry with missing column.\n",
    "    if (',' not in origin_str):\n",
    "        origin_str = origin_str + ',';\n",
    "    origin_list = origin_str.replace(\" \", \"\").upper().split(\",\")\n",
    "    if(origin_list[0].upper() == \"NAN\"):\n",
    "        origin_list[0] = \"\"\n",
    "    if(origin_list[1].upper() == \"NAN\"):\n",
    "        origin_list[1] = \"\"\n",
    "    # Convert possible number in entry.\n",
    "    if((not is_number(origin_list[0])) and (not is_number(origin_list[1]))):\n",
    "        origin_list[0] = numberConversion(origin_list[0])\n",
    "        origin_list[1] = numberConversion(origin_list[1])\n",
    "    genderSet = set(['F', 'M', 'OTHER'])\n",
    "    if (is_number(origin_list[0])):\n",
    "        # wrong entry (num, num)\n",
    "        if (is_number(origin_list[1])):\n",
    "            if (origin_list[0] == origin_list[1]):\n",
    "                return [None, origin_list[0]]\n",
    "            return [None, None]\n",
    "        else: # first number, second '' or gender (NOT num for sure)\n",
    "          # swap back number\n",
    "          origin_list = origin_list[::-1]\n",
    "          origin_list[0] = genderSpellingRewrite(origin_list[0])\n",
    "          return origin_list\n",
    "    else: \n",
    "        origin_list[0] = genderSpellingRewrite(origin_list[0])\n",
    "         # first '' or str, second is number\n",
    "        if (is_number(origin_list[1])):\n",
    "            return origin_list\n",
    "        else:\n",
    "            origin_list[1] = genderSpellingRewrite(origin_list[1])\n",
    "            if(origin_list[0] == origin_list[1]):\n",
    "               origin_list[1] = None\n",
    "            return origin_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BMI',\n",
       " 'TreatmentA',\n",
       " 'TreatmentB',\n",
       " 'TreatmentC',\n",
       " 'TreatmentD',\n",
       " 'average_blood_sugar',\n",
       " 'heart_condition_detected_2017',\n",
       " 'high_BP',\n",
       " 'id',\n",
       " 'married',\n",
       " 'sex and age',\n",
       " 'smoker_status',\n",
       " 'job_status',\n",
       " 'living_area']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sex_age_(df):\n",
    "    df[\"sex_age_list\"] = df[\"sex and age\"].astype(str).apply(lambda x: formatSexAge(x))\n",
    "    df[['sex','age']] = pd.DataFrame(df[\"sex_age_list\"].values.tolist(), index= df.index)\n",
    "    df[df[\"sex\"] == \"None\"][\"sex\"] = \"OTHER\"\n",
    "process_sex_age_(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Sex and Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_sex_age(sex_age_list):\n",
    "#     if type(sex_age_list) is not list:\n",
    "#         return [None,None]\n",
    "#     # Strip and Upper case both sex and age\n",
    "#     sex_age_list[0],sex_age_list[1] = sex_age_list[0].strip().upper(), sex_age_list[1].strip().upper()\n",
    "    \n",
    "#     # 2nd : first one is empty and second one is not numeric\n",
    "#     if (is_number(sex_age_list[0]) or (not sex_age_list[0] and not is_number(sex_age_list[1]))): \n",
    "#         sex_age_list = sex_age_list[::-1]\n",
    "#     sex = sex_age_list[0].strip().upper()\n",
    "    \n",
    "#     if sex in ('FEMALE','FEMALLE'):\n",
    "#         sex = 'F'\n",
    "#     if sex in ('MALE','MMALE','MM'):\n",
    "#         sex = 'M'\n",
    "\n",
    "#     sex_age_list[0] = sex\n",
    "#     sex_age_list[1] = sex_age_list[1]\n",
    "#     return sex_age_list\n",
    "\n",
    "# def process_sex_age(df):\n",
    "#     df[\"sex_age_list\"] = df[\"sex and age\"].str.split(\",\").apply(clean_sex_age)\n",
    "#     df[['sex','age']] = pd.DataFrame(df[\"sex_age_list\"].values.tolist(), index= df.index)\n",
    "#     df[\"age\"] = pd.to_numeric(df[\"age\"],errors='coerce').round()\n",
    "#     return df.drop(columns=[\"sex_age_list\",\"sex and age\"])\n",
    "# all_data = process_sex_age(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"age\"] = pd.to_numeric(all_data[\"age\"],errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(df):\n",
    "    return df[:ntrain], df[ntrain:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_train, preprocessed_test = split_train_test(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_categorical(df, columns):\n",
    "    for col in columns:\n",
    "        df[col] = df[col].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_by_mode(df,columns):\n",
    "    for col in columns:\n",
    "        df[col] = df[col].fillna(df[col].mode().iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_by_mode(all_data,[\"heart_condition_detected_2017\",\"high_BP\",\"married\"])#\"job_status\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"sex\"] = all_data[\"sex\"].fillna(\"OTHER\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute Age by Median group by sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = preprocessed_train.groupby(\"sex\")[\"age\"].median().reset_index(name=\"MedianAge\")\n",
    "df_merge = all_data.merge(df_tmp,on=\"sex\",how=\"left\")\n",
    "cond = df_merge['age'].isnull()\n",
    "df_merge['age'] = df_merge['age'].fillna(df_merge[\"MedianAge\"])\n",
    "all_data = df_merge.drop(columns=\"MedianAge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check missing value of smoker_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_categorical(all_data,[\"heart_condition_detected_2017\",\"married\",\"high_BP\",\"job_status\",\n",
    "                                 \"sex\",\"living_area\"])\n",
    "preprocessed_train, preprocessed_test = split_train_test(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BMI</th>\n",
       "      <th>TreatmentA</th>\n",
       "      <th>TreatmentB</th>\n",
       "      <th>TreatmentC</th>\n",
       "      <th>TreatmentD</th>\n",
       "      <th>average_blood_sugar</th>\n",
       "      <th>heart_condition_detected_2017</th>\n",
       "      <th>high_BP</th>\n",
       "      <th>id</th>\n",
       "      <th>married</th>\n",
       "      <th>sex and age</th>\n",
       "      <th>smoker_status</th>\n",
       "      <th>job_status</th>\n",
       "      <th>living_area</th>\n",
       "      <th>sex_age_list</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [BMI, TreatmentA, TreatmentB, TreatmentC, TreatmentD, average_blood_sugar, heart_condition_detected_2017, high_BP, id, married, sex and age, smoker_status, job_status, living_area, sex_age_list, sex, age]\n",
       "Index: []"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[all_data[\"living_area\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_predict_missing(df,missing_var,independent_var):\n",
    "    selected_cols = independent_var+[missing_var]\n",
    "    non_missing_data = preprocessed_train[preprocessed_train[missing_var].notnull()][selected_cols]\n",
    "    # Remove missing values\n",
    "    non_missing_data.dropna(inplace=True)\n",
    "    print(\"Training data for missing value \",non_missing_data.shape)\n",
    "    \n",
    "    # Build Random Forest classifier\n",
    "    clf = make_pipeline(OneHotEncoder(handle_unknown=\"ignore\"),RandomForestClassifier(n_estimators=500, max_depth=5))\n",
    "    clf.fit(non_missing_data[independent_var],non_missing_data[missing_var])\n",
    "    acc = np.mean(cross_val_score(clf,non_missing_data[independent_var],non_missing_data[missing_var],cv=5))\n",
    "    print(\"Random Forest Mean Accuracy for 5 runs of cross validation \", acc)\n",
    "    \n",
    "    # Predict missing values\n",
    "    cond = df[missing_var].isnull()\n",
    "    print(df[cond][independent_var])\n",
    "    df[cond][missing_var] = clf.predict(df[cond][independent_var])\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>average_blood_sugar</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoker_status</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>active_smoker</th>\n",
       "      <td>49.480394</td>\n",
       "      <td>111.703996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non-smoker</th>\n",
       "      <td>48.585128</td>\n",
       "      <td>109.809009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quit</th>\n",
       "      <td>57.281551</td>\n",
       "      <td>116.156170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     age  average_blood_sugar\n",
       "smoker_status                                \n",
       "active_smoker  49.480394           111.703996\n",
       "non-smoker     48.585128           109.809009\n",
       "quit           57.281551           116.156170"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(all_data[[\"smoker_status\",\"age\",\"average_blood_sugar\"]], index=[\"smoker_status\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>average_blood_sugar</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>living_area</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>None</th>\n",
       "      <td>49.025000</td>\n",
       "      <td>114.311250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city</th>\n",
       "      <td>45.241436</td>\n",
       "      <td>109.062748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>remote</th>\n",
       "      <td>45.204302</td>\n",
       "      <td>109.105874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   age  average_blood_sugar\n",
       "living_area                                \n",
       "None         49.025000           114.311250\n",
       "city         45.241436           109.062748\n",
       "remote       45.204302           109.105874"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(all_data[[\"living_area\",\"age\",\"average_blood_sugar\"]], index=[\"living_area\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>average_blood_sugar</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>married</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>24.241426</td>\n",
       "      <td>100.177172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>56.818551</td>\n",
       "      <td>114.008750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age  average_blood_sugar\n",
       "married                                \n",
       "0.0      24.241426           100.177172\n",
       "1.0      56.818551           114.008750"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(all_data[[\"married\",\"age\",\"average_blood_sugar\"]], index=[\"married\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data for missing value  (23207, 7)\n",
      "Random Forest Mean Accuracy for 5 runs of cross validation  0.503985699384212\n",
      "Empty DataFrame\n",
      "Columns: [job_status, age, BMI, high_BP, married, smoker_status]\n",
      "Index: []\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 6)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-b4a1b22103b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf_living_area\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf_predict_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"living_area\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"job_status\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"age\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"BMI\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"high_BP\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"married\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"smoker_status\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-30-8ec328e878f1>\u001b[0m in \u001b[0;36mrf_predict_missing\u001b[0;34m(df, missing_var, independent_var)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mcond\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_var\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindependent_var\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_var\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindependent_var\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;31m# update the docstring of the returned function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                 \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpredict_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    609\u001b[0m                                        copy=True)\n\u001b[1;32m    610\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py\u001b[0m in \u001b[0;36m_transform_new\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    562\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_transform_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0;34m\"\"\"New implementation assuming categorical input\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m         \u001b[0mX_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dtype'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_temp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py36/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    580\u001b[0m                              \u001b[0;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m                              % (n_samples, shape_repr, ensure_min_samples,\n\u001b[0;32m--> 582\u001b[0;31m                                 context))\n\u001b[0m\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_features\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 6)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "clf_living_area = rf_predict_missing(all_data,\"living_area\",[\"job_status\",\"age\", \"BMI\", \"high_BP\",\"married\", \"smoker_status\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_var = \"smoker_status\"\n",
    "independent_var = [\"BMI\",\"age\",\"sex\",\"married\",\"high_BP\",\"living_area\"]\n",
    "non_missing_data = preprocessed_train[preprocessed_train[missing_var].notnull()][independent_var+[missing_var]]\n",
    "non_missing_data[non_missing_data.isnull().any(axis=1)]\n",
    "non_missing_data.dropna(inplace=True)\n",
    "non_missing_data[non_missing_data.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "independent_var + [missing_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = all_data.profile_report(title='Medical Record Profiling Report')\n",
    "profile.to_file(output_file=\"train_data_summary.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
