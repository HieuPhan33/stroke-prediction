{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "import math\n",
    "import re\n",
    "import sklearn\n",
    "from sklearn.pipeline import make_pipeline,Pipeline\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import *\n",
    "from spellchecker import SpellChecker\n",
    "from word2number import w2n\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "sns.set_style('darkgrid')\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_number(s):\n",
    "    \"\"\" Returns True is string is a number. \"\"\"\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "train[\"stroke_in_2018\"]=train[\"stroke_in_2018\"].apply(lambda x: x if x in [\"0\",\"1\"] else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8718, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Duplicate data in train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(grp):\n",
    "    df = pd.DataFrame()\n",
    "    if(grp.shape[0] > 1):\n",
    "        for c in grp.columns:\n",
    "            value_counts = grp[c].value_counts().index.astype(grp[c].dtypes)\n",
    "            if value_counts.size > 1:\n",
    "                print(grp, value_counts) #Error\n",
    "            elif value_counts.size == 1:\n",
    "                df[c] = value_counts[0]\n",
    "            else:\n",
    "                df[c] = None\n",
    "    else:\n",
    "        df = grp.head(1)\n",
    "    return df\n",
    "train = train.groupby(\"id\").apply(merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  (34595, 14)\n"
     ]
    }
   ],
   "source": [
    "train = train[pd.notnull(train['stroke_in_2018'])] # Remove if target is NULL\n",
    "y_train = train[\"stroke_in_2018\"]\n",
    "print(\"Training \",train.shape)\n",
    "spell = SpellChecker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_data size is : (43313, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thien\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "ntrain = y_train.shape[0]\n",
    "all_data = pd.concat((train, test)).reset_index(drop=True)\n",
    "all_data.drop(['stroke_in_2018'], axis=1, inplace=True)\n",
    "print(\"all_data size is : {}\".format(all_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34595\n"
     ]
    }
   ],
   "source": [
    "print(ntrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_job_status_and_living_area_reversed(x):\n",
    "    return ((x[\"job_status\"] != None and x[\"job_status\"] in (\"r\", \"c\", \"city\", \"remote\", \"remotee\"))\n",
    "             or (x[\"living_area\"] != None and x[\"living_area\"] in (\"private_sector\", \"business_owner\")))\n",
    "def process_job_status(x):\n",
    "    if x == None or x in (\"nan\", 'null', \"\", 'n.a'):\n",
    "        return None\n",
    "    elif x in (\"private sector\", \"privattte\", \"private\", \"private_sector\"):\n",
    "        return \"private_sector\"\n",
    "    elif x in (\"government\", \"govt.\"):\n",
    "        return \"government\"\n",
    "    elif x in (\"business_owner\", \"business owner\", \"biz\"):\n",
    "        return \"business_owner\"\n",
    "    elif x in (\"parental_leave\", \"parental leave\"):\n",
    "        return \"parental_leave\"\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "def process_living_area(x):\n",
    "    if x == None or x in (\"nan\", 'null', \"\", 'n.a'):\n",
    "        return None\n",
    "    elif x == 'c':\n",
    "        return 'city'\n",
    "    elif x in ('r', 'remotee'):\n",
    "        return 'remote'\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "def split_job_status_and_living_area(x):\n",
    "    pair = x.lower().split(\"?\") if x != None else [x, x]\n",
    "    if len(pair) < 2:\n",
    "        pair = [pair[0], None]\n",
    "    return pair\n",
    "\n",
    "def process_job_status_and_living_area(df):\n",
    "    df[\"job_status\"] = df[\"job_status and living_area\"].astype(str).apply(split_job_status_and_living_area).apply(lambda x: x[0])\n",
    "    df[\"living_area\"] = df[\"job_status and living_area\"].astype(str).apply(split_job_status_and_living_area).apply(lambda x: x[1])\n",
    "    job_status = df.apply(lambda x: x[\"living_area\"] if is_job_status_and_living_area_reversed(x) else x[\"job_status\"], 1)\n",
    "    living_area = df.apply(lambda x: x[\"job_status\"] if is_job_status_and_living_area_reversed(x) else x[\"living_area\"], 1)\n",
    "    df[\"job_status\"] = job_status.apply(lambda x: process_job_status(x))\n",
    "    df[\"living_area\"] = living_area.apply(lambda x: process_living_area(x))\n",
    "    df.drop(columns='job_status and living_area',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_job_status_and_living_area(all_data)\n",
    "#process_job_status_and_living_area(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_smoker_status(x):\n",
    "    if x == None:\n",
    "        return None\n",
    "    elif x.startswith(\"non\"):\n",
    "        return \"non-smoker\"\n",
    "    elif x.startswith(\"quit\"):\n",
    "        return \"quit\"\n",
    "    elif x.startswith(\"active\"):\n",
    "        return \"active_smoker\"\n",
    "    else:\n",
    "        return None\n",
    "all_data[\"smoker_status\"] = all_data[\"smoker_status\"].astype(str).apply(process_smoker_status)\n",
    "#test[\"smoker_status\"] = test[\"smoker_status\"].astype(str).apply(process_smoker_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_binary_col(df,columns):\n",
    "    for col in columns:\n",
    "        df[col] = pd.to_numeric(df[col],errors=\"coerce\")\n",
    "        df[col] = df[col].astype(int,errors='ignore')\n",
    "        df[col] = df[col].apply(lambda x: x if x in [0,1] else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_binary_col(all_data,[\"heart_condition_detected_2017\",\"high_BP\",\"married\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert BMI to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"BMI\"] = pd.to_numeric(all_data[\"BMI\"],errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process gender into oneof \"F\", \"M\" and \"OTHER\"\n",
    "def genderSpellingRewrite(gender_str):\n",
    "    if not isinstance(gender_str, str):\n",
    "        return None;\n",
    "    uppered = gender_str.upper()\n",
    "    # Repeated single occurence should be truncate.\n",
    "    patternM = re.compile('[M]+$')\n",
    "    if (patternM.match(uppered)):\n",
    "        return \"M\"\n",
    "    patternF = re.compile('[F]+$')\n",
    "    if (patternF.match(uppered)):\n",
    "        return \"F\"\n",
    "    # Misspelling should be corrected and replaced.\n",
    "    # TODO: Malle is not going to be corrected as Male.Need to update spell's known list.\n",
    "    corrected = spell.correction(uppered).upper()\n",
    "    if (corrected == \"FEMALE\"):\n",
    "        return \"F\"\n",
    "    if (corrected == \"MALE\"):\n",
    "        return \"M\"\n",
    "    if (corrected == \"OTHER\"):\n",
    "        return \"OTHER\"\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process human number word into number\n",
    "def numberConversion(potential_number_word):\n",
    "    # Correct any possible miss spelled number_word\n",
    "    corrected_potential_word = spell.correction(potential_number_word)\n",
    "    # check it it means number\n",
    "    try:\n",
    "      potential_num = w2n.word_to_num(corrected_potential_word)\n",
    "    except ValueError:\n",
    "        return potential_number_word\n",
    "    return potential_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatSexAge(origin_str):\n",
    "    if not isinstance(origin_str, str):\n",
    "        return [None,None]\n",
    "    # Preprocess \n",
    "    # Entry with missing column.\n",
    "    if (',' not in origin_str):\n",
    "        origin_str = origin_str + ',';\n",
    "    origin_list = origin_str.replace(\" \", \"\").upper().split(\",\")\n",
    "    if(origin_list[0].upper() == \"NAN\"):\n",
    "        origin_list[0] = \"\"\n",
    "    if(origin_list[1].upper() == \"NAN\"):\n",
    "        origin_list[1] = \"\"\n",
    "    # Convert possible number in entry.\n",
    "    if((not is_number(origin_list[0])) and (not is_number(origin_list[1]))):\n",
    "        origin_list[0] = numberConversion(origin_list[0])\n",
    "        origin_list[1] = numberConversion(origin_list[1])\n",
    "    genderSet = set(['F', 'M', 'OTHER'])\n",
    "    if (is_number(origin_list[0])):\n",
    "        # wrong entry (num, num)\n",
    "        if (is_number(origin_list[1])):\n",
    "            if (origin_list[0] == origin_list[1]):\n",
    "                return [None, origin_list[0]]\n",
    "            return [None, None]\n",
    "        else: # first number, second '' or gender (NOT num for sure)\n",
    "          # swap back number\n",
    "          origin_list = origin_list[::-1]\n",
    "          origin_list[0] = genderSpellingRewrite(origin_list[0])\n",
    "          return origin_list\n",
    "    else: \n",
    "        origin_list[0] = genderSpellingRewrite(origin_list[0])\n",
    "         # first '' or str, second is number\n",
    "        if (is_number(origin_list[1])):\n",
    "            return origin_list\n",
    "        else:\n",
    "            origin_list[1] = genderSpellingRewrite(origin_list[1])\n",
    "            if(origin_list[0] == origin_list[1]):\n",
    "               origin_list[1] = None\n",
    "            return origin_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sex_age_(df):\n",
    "    df[\"sex_age_list\"] = df[\"sex and age\"].astype(str).apply(lambda x: formatSexAge(x))\n",
    "    df[['sex','age']] = pd.DataFrame(df[\"sex_age_list\"].values.tolist(), index= df.index)\n",
    "    df[df[\"sex\"] == \"None\"][\"sex\"] = \"OTHER\"\n",
    "process_sex_age_(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Sex and Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"age\"] = pd.to_numeric(all_data[\"age\"],errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(df):\n",
    "    print(\"Train shape \",df[:ntrain].shape)\n",
    "    print(\"Test shape \",df[ntrain:].shape)\n",
    "    return df[:ntrain], df[ntrain:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape  (34595, 17)\n",
      "Test shape  (8718, 17)\n"
     ]
    }
   ],
   "source": [
    "preprocessed_train, preprocessed_test = split_train_test(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_categorical(df, columns):\n",
    "    for col in columns:\n",
    "        df[col] = df[col].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_by_mode(df,columns):\n",
    "    for col in columns:\n",
    "        df[col] = df[col].fillna(df[col].mode().iloc[0])\n",
    "def impute_by_median(df,columns):\n",
    "    for col in columns:\n",
    "        df[col] = df[col].fillna(df[col].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_by_mode(all_data,[\"heart_condition_detected_2017\",\"high_BP\",\"married\",\"job_status\"])\n",
    "impute_by_median(all_data,[\"average_blood_sugar\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"sex\"] = all_data[\"sex\"].fillna(\"OTHER\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute Age by Median group by sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = preprocessed_train.groupby(\"sex\")[\"age\"].median().reset_index(name=\"MedianAge\")\n",
    "df_merge = all_data.merge(df_tmp,on=\"sex\",how=\"left\")\n",
    "cond = df_merge['age'].isnull()\n",
    "df_merge['age'] = df_merge['age'].fillna(df_merge[\"MedianAge\"])\n",
    "all_data = df_merge.drop(columns=\"MedianAge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check missing value of smoker_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape  (34595, 17)\n",
      "Test shape  (8718, 17)\n"
     ]
    }
   ],
   "source": [
    "convert_to_categorical(all_data,[\"heart_condition_detected_2017\",\"married\",\"high_BP\",\"job_status\",\n",
    "                                 \"sex\",\"living_area\"])\n",
    "preprocessed_train, preprocessed_test = split_train_test(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_missing(df,missing_var,independent_var,model):\n",
    "    selected_cols = independent_var+[missing_var]\n",
    "    non_missing_data = df[df[missing_var].notnull()][selected_cols]\n",
    "    # Remove missing values\n",
    "    non_missing_data = non_missing_data.dropna()\n",
    "    print(\"Training data for missing value \",non_missing_data.shape)\n",
    "    \n",
    "    # Build Random Forest classifier\n",
    "    clf = make_pipeline(OneHotEncoder(handle_unknown=\"ignore\"),model)\n",
    "    clf.fit(non_missing_data[independent_var],non_missing_data[missing_var])\n",
    "    acc = np.mean(cross_val_score(clf,non_missing_data[independent_var],non_missing_data[missing_var],cv=5))\n",
    "    print(\"Random Forest Mean Accuracy for 5 runs of cross validation \", acc)\n",
    "    \n",
    "    # Predict missing values\n",
    "    cond = df[missing_var].isnull()\n",
    "    df[cond][missing_var] = clf.predict(df[cond][independent_var])\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data for missing value  (30045, 7)\n",
      "Random Forest Mean Accuracy for 5 runs of cross validation  0.5331336398924217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thien\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "clf = predict_missing(all_data,\"smoker_status\",[\"age\",\"sex\",\"married\",\"high_BP\",\"living_area\",\"average_blood_sugar\"],\n",
    "                        RandomForestClassifier(n_estimators=600, max_depth=7))\n",
    "# clf = rf_predict_missing(all_data,\"\",[\"BMI\",\"age\",\"sex\",\"high_BP\",\"married\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impute_by_median(all_data,[\"BMI\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data for missing value  (41847, 8)\n",
      "Random Forest Mean Accuracy for 5 runs of cross validation  0.3804090223181906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thien\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('onehotencoder',\n",
       "                 OneHotEncoder(categorical_features=None, categories=None,\n",
       "                               drop=None, dtype=<class 'numpy.float64'>,\n",
       "                               handle_unknown='ignore', n_values=None,\n",
       "                               sparse=True)),\n",
       "                ('adaboostclassifier',\n",
       "                 AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "                                    learning_rate=1.0, n_estimators=50,\n",
       "                                    random_state=None))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bmi_category(bmi):\n",
    "    if pd.isnull(bmi):\n",
    "        return np.nan\n",
    "    if bmi > 35:\n",
    "        return \"SO\"\n",
    "    elif bmi > 30:\n",
    "        return \"MO\"\n",
    "    elif bmi > 25:\n",
    "        return \"O\"\n",
    "    elif bmi > 18.5:\n",
    "        return \"N\"\n",
    "    else:\n",
    "        return \"U\"\n",
    "\n",
    "all_data[\"bmi_category\"] = all_data[\"BMI\"].apply(bmi_category)\n",
    "predict_missing(all_data,\"bmi_category\", [\"job_status\", \"high_BP\", \"heart_condition_detected_2017\",\n",
    "                                             \"married\", \"age\", \"sex\", \"average_blood_sugar\"],AdaBoostClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_vars = [\"sex\",\"age\",\"high_BP\",\"heart_condition_detected_2017\",\n",
    "                \"married\",\"job_status\",\"living_area\",\"average_blood_sugar\",\n",
    "                \"bmi_category\",\"smoker_status\"]\n",
    "selected_data = all_data[selected_vars]\n",
    "selected_data = pd.get_dummies(selected_data).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data  (34595, 27)  target  (34595,)\n",
      "Testing data (8718, 27)\n"
     ]
    }
   ],
   "source": [
    "X_train = selected_data[:ntrain]\n",
    "X_test = selected_data[ntrain:]\n",
    "print(\"Training data \",X_train.shape, \" target \",y_train.shape)\n",
    "print(\"Testing data\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore Data Complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot2D(X,y):\n",
    "    df_tsne = pd.DataFrame()\n",
    "    df_tsne['stroke'] = y\n",
    "    tsne = TSNE(n_components=2, verbose=1, perplexity=50, n_iter=3000)\n",
    "    tsne_results = tsne.fit_transform(X)\n",
    "    df_tsne['tsne_v1'] = tsne_results[:,0]\n",
    "    df_tsne['tsne_v2'] = tsne_results[:,1]\n",
    "    # Make the plot\n",
    "    sns.scatterplot(\n",
    "        x=\"tsne_v1\", y=\"tsne_v2\",\n",
    "        hue=\"stroke\",\n",
    "        palette=sns.hls_palette(2, l=.3, s=.9),\n",
    "        data=df_tsne,\n",
    "        legend=\"full\",\n",
    "        alpha=0.3\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = all_data.profile_report(title='Medical Record Profiling Report')\n",
    "profile.to_file(output_file=\"train_data_summary.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    33947\n",
       "1      648\n",
       "Name: stroke_in_2018, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier, EasyEnsembleClassifier, RUSBoostClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "#plot_2d_space(X_cc, y_cc, 'Cluster Centroids under-sampling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BalancedRandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BalancedRandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                               criterion='gini', max_depth=None,\n",
       "                               max_features='auto', max_leaf_nodes=None,\n",
       "                               min_impurity_decrease=0.0, min_samples_leaf=2,\n",
       "                               min_samples_split=2,\n",
       "                               min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                               n_jobs=1, oob_score=False, random_state=None,\n",
       "                               replacement=False, sampling_strategy='auto',\n",
       "                               verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0722314686619338"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_train, model.predict_proba(X_train)[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99144791, 0.42049333, 0.65002494, ..., 0.43112784, 0.57973399,\n",
       "       0.34024432])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = ClusterCentroids(ratio={\"0\": 4000})\n",
    "X_cc, y_cc = cc.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cc = y_cc.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START ML 2019-07-21 07:56:20.072139\n"
     ]
    }
   ],
   "source": [
    "print('START ML', datetime.now(), )\n",
    "kfolds = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "def grid_search(X_train, y_train, model, param_grid, scoring=[\"roc_auc\"], refit=\"roc_auc\"):\n",
    "    gs = GridSearchCV(model,param_grid=param_grid,scoring=scoring,refit=refit,cv=kfolds, n_jobs = -1)\n",
    "    gs.fit(X_train,y_train)\n",
    "    results = gs.cv_results_\n",
    "    print(refit,\" =\",gs.best_score_,\" achieved by configuration : \",gs.best_params_)\n",
    "    best_idx = np.argwhere(results['rank_test_%s' % refit] == 1)[0,0]\n",
    "    for scorer in scoring:\n",
    "        for sample in ['test']:\n",
    "            sample_score_mean = results['mean_%s_%s' % (sample, scorer)][best_idx]\n",
    "            print(sample,\"_\",scorer,\":\",sample_score_mean)\n",
    "    return gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc  = 0.8560527105082113  achieved by configuration :  {'n_estimators': 100, 'replacement': False, 'sampling_strategy': 'not majority'}\n",
      "test _ roc_auc : 0.8560527105082113\n"
     ]
    }
   ],
   "source": [
    "model = RUSBoostClassifier()\n",
    "best_rf = grid_search(X_train, y_train, model, param_grid = {\"n_estimators\": [100, 200, 500], \"replacement\": [True, False], \"sampling_strategy\": [\"not majority\", \"not minority\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rf = best_rf.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.395174    100\n",
       "0.394781     75\n",
       "0.394796     70\n",
       "0.394404     63\n",
       "0.394518     42\n",
       "0.395390     40\n",
       "0.394526     34\n",
       "0.394140     34\n",
       "0.486059     32\n",
       "0.394904     31\n",
       "0.397287     31\n",
       "0.395153     26\n",
       "0.395012     26\n",
       "0.485649     26\n",
       "0.486748     25\n",
       "0.395917     25\n",
       "0.486338     25\n",
       "0.397666     23\n",
       "0.485971     23\n",
       "0.487143     23\n",
       "0.395172     23\n",
       "0.396295     22\n",
       "0.394775     22\n",
       "0.396894     21\n",
       "0.397273     21\n",
       "0.486381     20\n",
       "0.486608     20\n",
       "0.395550     20\n",
       "0.486776     19\n",
       "0.472650     19\n",
       "           ... \n",
       "0.494157      1\n",
       "0.495334      1\n",
       "0.473622      1\n",
       "0.491945      1\n",
       "0.490656      1\n",
       "0.481216      1\n",
       "0.491187      1\n",
       "0.483377      1\n",
       "0.492880      1\n",
       "0.492861      1\n",
       "0.489489      1\n",
       "0.394791      1\n",
       "0.472413      1\n",
       "0.491138      1\n",
       "0.483071      1\n",
       "0.492622      1\n",
       "0.492027      1\n",
       "0.486011      1\n",
       "0.486874      1\n",
       "0.492177      1\n",
       "0.488449      1\n",
       "0.480642      1\n",
       "0.493410      1\n",
       "0.495465      1\n",
       "0.491383      1\n",
       "0.488434      1\n",
       "0.489630      1\n",
       "0.472735      1\n",
       "0.490461      1\n",
       "0.497856      1\n",
       "Length: 4718, dtype: int64"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_rf).astype(float).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit = pd.DataFrame()\n",
    "df_submit[\"id\"] = test[\"id\"]\n",
    "df_submit[\"stroke_in_2018\"] = pd.Series(y_rf).astype(float)\n",
    "df_submit.to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc_auc  = 0.8565332515066911  achieved by configuration :  {'base_estimator': GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "                           max_features=None, max_leaf_nodes=None,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=2,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                           n_iter_no_change=None, presort='auto',\n",
      "                           random_state=None, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False)}\n",
      "test _ roc_auc : 0.8565332515066911\n"
     ]
    }
   ],
   "source": [
    "model = EasyEnsembleClassifier(n_estimators = 50)\n",
    "best_ensemble = grid_search(X_train, y_train, model, param_grid = {\"base_estimator\" : [BaggingClassifier(), AdaBoostClassifier(), ExtraTreesClassifier(), GradientBoostingClassifier(), GradientBoostingClassifier(loss = \"exponential\"), RandomForestClassifier()] })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ensemble = best_ensemble.predict(X_test)\n",
    "df_submit = pd.DataFrame()\n",
    "df_submit[\"id\"] = test[\"id\"]\n",
    "df_submit[\"stroke_in_2018\"] = pd.Series(y_ensemble)\n",
    "df_submit.to_csv(\"submission.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
