{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "import math\n",
    "import re\n",
    "from sklearn.pipeline import make_pipeline,Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from spellchecker import SpellChecker\n",
    "from word2number import w2n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_number(s):\n",
    "    \"\"\" Returns True is string is a number. \"\"\"\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "spell = SpellChecker()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Duplicate data in train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(grp):\n",
    "    df = pd.DataFrame()\n",
    "    if(grp.shape[0] > 1):\n",
    "        for c in grp.columns:\n",
    "            value_counts = grp[c].value_counts().index.astype(grp[c].dtypes)\n",
    "            if value_counts.size > 1:\n",
    "                print(grp, value_counts) #Error\n",
    "            elif value_counts.size == 1:\n",
    "                df[c] = value_counts[0]\n",
    "            else:\n",
    "                df[c] = None\n",
    "    else:\n",
    "        df = grp.head(1)\n",
    "    return df\n",
    "train = train.groupby(\"id\").apply(merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_data size is : (43342, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Program\\Anaconda\\envs\\NLP\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "ntrain = train.shape[0]\n",
    "ntest = train.shape[0]\n",
    "all_data = pd.concat((train, test)).reset_index(drop=True)\n",
    "all_data.drop(['stroke_in_2018'], axis=1, inplace=True)\n",
    "print(\"all_data size is : {}\".format(all_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_job_status_and_living_area_reversed(x):\n",
    "    return ((x[\"job_status\"] != None and x[\"job_status\"] in (\"r\", \"c\", \"city\", \"remote\", \"remotee\"))\n",
    "             or (x[\"living_area\"] != None and x[\"living_area\"] in (\"private_sector\", \"business_owner\")))\n",
    "def process_job_status(x):\n",
    "    if x == None or x in (\"nan\", 'null', \"\", 'n.a'):\n",
    "        return None\n",
    "    elif x in (\"private sector\", \"privattte\", \"private\", \"private_sector\"):\n",
    "        return \"private_sector\"\n",
    "    elif x in (\"government\", \"govt.\"):\n",
    "        return \"government\"\n",
    "    elif x in (\"business_owner\", \"business owner\", \"biz\"):\n",
    "        return \"business_owner\"\n",
    "    elif x in (\"parental_leave\", \"parental leave\"):\n",
    "        return \"parental_leave\"\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "def process_living_area(x):\n",
    "    if x == None or x in (\"nan\", 'null', \"\", 'n.a'):\n",
    "        return None\n",
    "    elif x == 'c':\n",
    "        return 'city'\n",
    "    elif x in ('r', 'remotee'):\n",
    "        return 'remote'\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "def split_job_status_and_living_area(x):\n",
    "    pair = x.lower().split(\"?\") if x != None else [x, x]\n",
    "    if len(pair) < 2:\n",
    "        pair = [pair[0], None]\n",
    "    return pair\n",
    "\n",
    "def process_job_status_and_living_area(df):\n",
    "    df[\"job_status\"] = df[\"job_status and living_area\"].astype(str).apply(split_job_status_and_living_area).apply(lambda x: x[0])\n",
    "    df[\"living_area\"] = df[\"job_status and living_area\"].astype(str).apply(split_job_status_and_living_area).apply(lambda x: x[1])\n",
    "    job_status = df.apply(lambda x: x[\"living_area\"] if is_job_status_and_living_area_reversed(x) else x[\"job_status\"], 1)\n",
    "    living_area = df.apply(lambda x: x[\"job_status\"] if is_job_status_and_living_area_reversed(x) else x[\"living_area\"], 1)\n",
    "    df[\"job_status\"] = job_status.apply(lambda x: process_job_status(x))\n",
    "    df[\"living_area\"] = living_area.apply(lambda x: process_living_area(x))\n",
    "    df.drop(columns='job_status and living_area',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_job_status_and_living_area(all_data)\n",
    "#process_job_status_and_living_area(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_smoker_status(x):\n",
    "    if x == None:\n",
    "        return None\n",
    "    elif x.startswith(\"non\"):\n",
    "        return \"non-smoker\"\n",
    "    elif x.startswith(\"quit\"):\n",
    "        return \"quit\"\n",
    "    elif x.startswith(\"active\"):\n",
    "        return \"active_smoker\"\n",
    "    else:\n",
    "        return None\n",
    "all_data[\"smoker_status\"] = all_data[\"smoker_status\"].astype(str).apply(process_smoker_status)\n",
    "#test[\"smoker_status\"] = test[\"smoker_status\"].astype(str).apply(process_smoker_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_binary_col(df,columns):\n",
    "    for col in columns:\n",
    "        df[col] = pd.to_numeric(df[col],errors=\"coerce\")\n",
    "        df[col] = df[col].astype(int,errors='ignore')\n",
    "        df[col] = df[col].apply(lambda x: x if x in [0,1] else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_binary_col(all_data,[\"heart_condition_detected_2017\",\"high_BP\",\"married\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert BMI to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"BMI\"] = pd.to_numeric(all_data[\"BMI\"],errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process gender into oneof \"F\", \"M\" and \"OTHER\"\n",
    "def genderSpellingRewrite(gender_str):\n",
    "    if not isinstance(gender_str, str):\n",
    "        return None;\n",
    "    uppered = gender_str.upper()\n",
    "    # Repeated single occurence should be truncate.\n",
    "    patternM = re.compile('[M]+$')\n",
    "    if (patternM.match(uppered)):\n",
    "        return \"M\"\n",
    "    patternF = re.compile('[F]+$')\n",
    "    if (patternF.match(uppered)):\n",
    "        return \"F\"\n",
    "    # Misspelling should be corrected and replaced.\n",
    "    # TODO: Malle is not going to be corrected as Male.Need to update spell's known list.\n",
    "    corrected = spell.correction(uppered).upper()\n",
    "    if (corrected == \"FEMALE\"):\n",
    "        return \"F\"\n",
    "    if (corrected == \"MALE\"):\n",
    "        return \"M\"\n",
    "    if (corrected == \"OTHER\"):\n",
    "        return \"OTHER\"\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process human number word into number\n",
    "def numberConversion(potential_number_word):\n",
    "    # Correct any possible miss spelled number_word\n",
    "    corrected_potential_word = spell.correction(potential_number_word)\n",
    "    # check it it means number\n",
    "    try:\n",
    "      potential_num = w2n.word_to_num(corrected_potential_word)\n",
    "    except ValueError:\n",
    "        return potential_number_word\n",
    "    return potential_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatSexAge(origin_str):\n",
    "    if not isinstance(origin_str, str):\n",
    "        return [None,None]\n",
    "    # Preprocess \n",
    "    # Entry with missing column.\n",
    "    if (',' not in origin_str):\n",
    "        origin_str = origin_str + ',';\n",
    "    origin_list = origin_str.replace(\" \", \"\").upper().split(\",\")\n",
    "    if(origin_list[0].upper() == \"NAN\"):\n",
    "        origin_list[0] = \"\"\n",
    "    if(origin_list[1].upper() == \"NAN\"):\n",
    "        origin_list[1] = \"\"\n",
    "    # Convert possible number in entry.\n",
    "    if((not is_number(origin_list[0])) and (not is_number(origin_list[1]))):\n",
    "        origin_list[0] = numberConversion(origin_list[0])\n",
    "        origin_list[1] = numberConversion(origin_list[1])\n",
    "    genderSet = set(['F', 'M', 'OTHER'])\n",
    "    if (is_number(origin_list[0])):\n",
    "        # wrong entry (num, num)\n",
    "        if (is_number(origin_list[1])):\n",
    "            if (origin_list[0] == origin_list[1]):\n",
    "                return [None, origin_list[0]]\n",
    "            return [None, None]\n",
    "        else: # first number, second '' or gender (NOT num for sure)\n",
    "          # swap back number\n",
    "          origin_list = origin_list[::-1]\n",
    "          origin_list[0] = genderSpellingRewrite(origin_list[0])\n",
    "          return origin_list\n",
    "    else: \n",
    "        origin_list[0] = genderSpellingRewrite(origin_list[0])\n",
    "         # first '' or str, second is number\n",
    "        if (is_number(origin_list[1])):\n",
    "            return origin_list\n",
    "        else:\n",
    "            origin_list[1] = genderSpellingRewrite(origin_list[1])\n",
    "            if(origin_list[0] == origin_list[1]):\n",
    "               origin_list[1] = None\n",
    "            return origin_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BMI',\n",
       " 'TreatmentA',\n",
       " 'TreatmentB',\n",
       " 'TreatmentC',\n",
       " 'TreatmentD',\n",
       " 'average_blood_sugar',\n",
       " 'heart_condition_detected_2017',\n",
       " 'high_BP',\n",
       " 'id',\n",
       " 'married',\n",
       " 'sex and age',\n",
       " 'smoker_status',\n",
       " 'job_status',\n",
       " 'living_area']"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sex_age_(df):\n",
    "    df[\"sex_age_list\"] = df[\"sex and age\"].astype(str).apply(lambda x: formatSexAge(x))\n",
    "    df[['sex','age']] = pd.DataFrame(df[\"sex_age_list\"].values.tolist(), index= df.index)\n",
    "    df[df[\"sex\"] == \"None\"][\"sex\"] = \"OTHER\"\n",
    "process_sex_age_(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Sex and Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_sex_age(sex_age_list):\n",
    "#     if type(sex_age_list) is not list:\n",
    "#         return [None,None]\n",
    "#     # Strip and Upper case both sex and age\n",
    "#     sex_age_list[0],sex_age_list[1] = sex_age_list[0].strip().upper(), sex_age_list[1].strip().upper()\n",
    "    \n",
    "#     # 2nd : first one is empty and second one is not numeric\n",
    "#     if (is_number(sex_age_list[0]) or (not sex_age_list[0] and not is_number(sex_age_list[1]))): \n",
    "#         sex_age_list = sex_age_list[::-1]\n",
    "#     sex = sex_age_list[0].strip().upper()\n",
    "    \n",
    "#     if sex in ('FEMALE','FEMALLE'):\n",
    "#         sex = 'F'\n",
    "#     if sex in ('MALE','MMALE','MM'):\n",
    "#         sex = 'M'\n",
    "\n",
    "#     sex_age_list[0] = sex\n",
    "#     sex_age_list[1] = sex_age_list[1]\n",
    "#     return sex_age_list\n",
    "\n",
    "# def process_sex_age(df):\n",
    "#     df[\"sex_age_list\"] = df[\"sex and age\"].str.split(\",\").apply(clean_sex_age)\n",
    "#     df[['sex','age']] = pd.DataFrame(df[\"sex_age_list\"].values.tolist(), index= df.index)\n",
    "#     df[\"age\"] = pd.to_numeric(df[\"age\"],errors='coerce').round()\n",
    "#     return df.drop(columns=[\"sex_age_list\",\"sex and age\"])\n",
    "# all_data = process_sex_age(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"age\"] = pd.to_numeric(all_data[\"age\"],errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(df):\n",
    "    return df[:ntrain], df[ntrain:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_train, preprocessed_test = split_train_test(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_categorical(df, columns):\n",
    "    for col in columns:\n",
    "        df[col] = df[col].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_by_mode(df,columns):\n",
    "    for col in columns:\n",
    "        df[col] = df[col].fillna(df[col].mode().iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_by_mode(all_data,[\"heart_condition_detected_2017\",\"high_BP\",\"married\",\"job_status\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"sex\"] = all_data[\"sex\"].fillna(\"OTHER\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute Age by Median group by sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = preprocessed_train.groupby(\"sex\")[\"age\"].median().reset_index(name=\"MedianAge\")\n",
    "df_merge = all_data.merge(df_tmp,on=\"sex\",how=\"left\")\n",
    "cond = df_merge['age'].isnull()\n",
    "df_merge['age'] = df_merge['age'].fillna(df_merge[\"MedianAge\"])\n",
    "all_data = df_merge.drop(columns=\"MedianAge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check missing value of smoker_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_categorical(all_data,[\"heart_condition_detected_2017\",\"married\",\"high_BP\",\"job_status\",\n",
    "                                 \"sex\",\"living_area\"])\n",
    "preprocessed_train, preprocessed_test = split_train_test(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_predict_missing(df,missing_var,independent_var):\n",
    "    selected_cols = independent_var+[missing_var]\n",
    "    non_missing_data = preprocessed_train[preprocessed_train[missing_var].notnull()][selected_cols]\n",
    "    # Remove missing values\n",
    "    non_missing_data.dropna(inplace=True)\n",
    "    print(\"Training data for missing value \",non_missing_data.shape)\n",
    "    \n",
    "    # Build Random Forest classifier\n",
    "    clf = make_pipeline(OneHotEncoder(handle_unknown=\"ignore\"),RandomForestClassifier(n_estimators=500, max_depth=5))\n",
    "    clf.fit(non_missing_data[independent_var],non_missing_data[missing_var])\n",
    "    acc = np.mean(cross_val_score(clf,non_missing_data[independent_var],non_missing_data[missing_var],cv=5))\n",
    "    print(\"Random Forest Mean Accuracy for 5 runs of cross validation \", acc)\n",
    "    \n",
    "    # Predict missing values\n",
    "    cond = df[missing_var].isnull()\n",
    "    df[cond][missing_var] = clf.predict(df[cond][independent_var])\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data for missing value  (23207, 7)\n",
      "Random Forest Mean Accuracy for 5 runs of cross validation  0.5387167720756791\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-266-e26b8a5f3804>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf_predict_missing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"smoker_status\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"BMI\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"age\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"sex\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"married\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"high_BP\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"living_area\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-265-1d1dd36aea68>\u001b[0m in \u001b[0;36mrf_predict_missing\u001b[1;34m(df, missing_var, independent_var)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m# Predict missing values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mcond\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmissing_var\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcond\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmissing_var\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcond\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindependent_var\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program\\Anaconda\\envs\\NLP\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m         \u001b[1;31m# update the docstring of the returned function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program\\Anaconda\\envs\\NLP\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, **predict_params)\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 331\u001b[1;33m                 \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    332\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpredict_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program\\Anaconda\\envs\\NLP\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    609\u001b[0m                                        copy=True)\n\u001b[0;32m    610\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transform_new\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program\\Anaconda\\envs\\NLP\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36m_transform_new\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mX_int\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle_unknown\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle_unknown\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m         \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program\\Anaconda\\envs\\NLP\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36m_transform\u001b[1;34m(self, X, handle_unknown)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle_unknown\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_X\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Program\\Anaconda\\envs\\NLP\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py\u001b[0m in \u001b[0;36m_check_X\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_get_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'assume_finite'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0m_object_dtype_isnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Input contains NaN\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN"
     ]
    }
   ],
   "source": [
    "#clf = rf_predict_missing(all_data,\"smoker_status\",[\"BMI\",\"age\",\"sex\",\"married\",\"high_BP\",\"living_area\"])\n",
    "clf = rf_predict_missing(all_data,\"job_status\",[\"BMI\",\"age\",\"sex\",\"married\",\"high_BP\",\"marrie\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Program\\Anaconda\\envs\\NLP\\lib\\site-packages\\sklearn\\model_selection\\_split.py:652: Warning: The least populated class in y has only 3 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Mean Accuracy for 5 runs of cross validation  0.5559507680361762\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BMI</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>married</th>\n",
       "      <th>high_BP</th>\n",
       "      <th>living_area</th>\n",
       "      <th>smoker_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [BMI, age, sex, married, high_BP, living_area, smoker_status]\n",
       "Index: []"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_var = \"smoker_status\"\n",
    "independent_var = [\"BMI\",\"age\",\"sex\",\"married\",\"high_BP\",\"living_area\"]\n",
    "non_missing_data = preprocessed_train[preprocessed_train[missing_var].notnull()][independent_var+[missing_var]]\n",
    "non_missing_data[non_missing_data.isnull().any(axis=1)]\n",
    "non_missing_data.dropna(inplace=True)\n",
    "non_missing_data[non_missing_data.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BMI', 'age', 'sex', 'married', 'high_BP', 'living_area', 'smoker_status']"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "independent_var + [missing_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = all_data.profile_report(title='Medical Record Profiling Report')\n",
    "profile.to_file(output_file=\"train_data_summary.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
