{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "import math\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_number(s):\n",
    "    \"\"\" Returns True is string is a number. \"\"\"\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_data size is : (43590, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Program\\Anaconda\\envs\\NLP\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "ntrain = train.shape[0]\n",
    "ntest = train.shape[0]\n",
    "all_data = pd.concat((train, test)).reset_index(drop=True)\n",
    "all_data.drop(['stroke_in_2018'], axis=1, inplace=True)\n",
    "print(\"all_data size is : {}\".format(all_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_job_status_and_living_area_reversed(x):\n",
    "    return ((x[\"job_status\"] != None and x[\"job_status\"] in (\"r\", \"c\", \"city\", \"remote\", \"remotee\"))\n",
    "             or (x[\"living_area\"] != None and x[\"living_area\"] in (\"private_sector\", \"business_owner\")))\n",
    "def process_job_status(x):\n",
    "    if x == None or x in (\"nan\", 'null', \"\", 'n.a'):\n",
    "        return None\n",
    "    elif x in (\"private sector\", \"privattte\", \"private\", \"private_sector\"):\n",
    "        return \"private_sector\"\n",
    "    elif x in (\"government\", \"govt.\"):\n",
    "        return \"government\"\n",
    "    elif x in (\"business_owner\", \"business owner\", \"biz\"):\n",
    "        return \"business_owner\"\n",
    "    elif x in (\"parental_leave\", \"parental leave\"):\n",
    "        return \"parental_leave\"\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "def process_living_area(x):\n",
    "    if x == None or x in (\"nan\", 'null', \"\", 'n.a'):\n",
    "        return None\n",
    "    elif x == 'c':\n",
    "        return 'city'\n",
    "    elif x in ('r', 'remotee'):\n",
    "        return 'remote'\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "def split_job_status_and_living_area(x):\n",
    "    pair = x.lower().split(\"?\") if x != None else [x, x]\n",
    "    if len(pair) < 2:\n",
    "        pair = [pair[0], None]\n",
    "    return pair\n",
    "\n",
    "def process_job_status_and_living_area(df):\n",
    "    df[\"job_status\"] = df[\"job_status and living_area\"].astype(str).apply(split_job_status_and_living_area).apply(lambda x: x[0])\n",
    "    df[\"living_area\"] = df[\"job_status and living_area\"].astype(str).apply(split_job_status_and_living_area).apply(lambda x: x[1])\n",
    "    job_status = df.apply(lambda x: x[\"living_area\"] if is_job_status_and_living_area_reversed(x) else x[\"job_status\"], 1)\n",
    "    living_area = df.apply(lambda x: x[\"job_status\"] if is_job_status_and_living_area_reversed(x) else x[\"living_area\"], 1)\n",
    "    df[\"job_status\"] = job_status.apply(lambda x: process_job_status(x))\n",
    "    df[\"living_area\"] = living_area.apply(lambda x: process_living_area(x))\n",
    "    df.drop(columns='job_status and living_area',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_job_status_and_living_area(all_data)\n",
    "#process_job_status_and_living_area(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_smoker_status(x):\n",
    "    if x == None:\n",
    "        return None\n",
    "    elif x.startswith(\"non\"):\n",
    "        return \"non-smoker\"\n",
    "    elif x.startswith(\"quit\"):\n",
    "        return \"quit\"\n",
    "    elif x.startswith(\"active\"):\n",
    "        return \"active_smoker\"\n",
    "    else:\n",
    "        return None\n",
    "all_data[\"smoker_status\"] = all_data[\"smoker_status\"].astype(str).apply(process_smoker_status)\n",
    "#test[\"smoker_status\"] = test[\"smoker_status\"].astype(str).apply(process_smoker_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert BMI to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"BMI\"] = pd.to_numeric(all_data[\"BMI\"],errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treat '.,' as Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_invalid_binary_values(df,columns):\n",
    "    for col in columns:\n",
    "        df[~df[col].isin([\"0\",\"1\"])] = None\n",
    "#replace_invalid_binary_values(all_data,[\"high_BP\",\"stroke_in_2018\",\"married\"])\n",
    "replace_invalid_binary_values(all_data,[\"high_BP\",\"heart_condition_detected_2017\",\"married\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean Sex and Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sex_age(sex_age_list):\n",
    "    if type(sex_age_list) is not list:\n",
    "        return [None,None]\n",
    "    # Strip and Upper case both sex and age\n",
    "    sex_age_list[0],sex_age_list[1] = sex_age_list[0].strip().upper(), sex_age_list[1].strip().upper()\n",
    "    \n",
    "    # 2nd : first one is empty and second one is not numeric\n",
    "    if (is_number(sex_age_list[0]) or (not sex_age_list[0] and not is_number(sex_age_list[1]))): \n",
    "        sex_age_list = sex_age_list[::-1]\n",
    "    sex = sex_age_list[0].strip().upper()\n",
    "    \n",
    "    # Take\n",
    "    if sex in ('FEMALE','FEMALLE'):\n",
    "        sex = 'F'\n",
    "    if sex in ('MALE','MMALE','MM'):\n",
    "        sex = 'M'\n",
    "\n",
    "    sex_age_list[0] = sex\n",
    "    sex_age_list[1] = sex_age_list[1]\n",
    "    return sex_age_list\n",
    "def process_sex_age(df):\n",
    "    df[\"sex_age_list\"] = df[\"sex and age\"].str.split(\",\").apply(clean_sex_age)\n",
    "    df[['sex','age']] = pd.DataFrame(df[\"sex_age_list\"].values.tolist(), index= df.index)\n",
    "    df[\"age\"] = pd.to_numeric(df[\"age\"],errors='coerce').round()\n",
    "    return df.drop(columns=[\"sex_age_list\",\"sex and age\"])\n",
    "all_data = process_sex_age(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(grp):\n",
    "    df = pd.DataFrame()\n",
    "    if(grp.shape[0] > 1):\n",
    "        for c in grp.columns:\n",
    "            value_counts = grp[c].value_counts().index.astype(grp[c].dtypes)\n",
    "            if value_counts.size > 1:\n",
    "                print(grp, value_counts) #Error\n",
    "            elif value_counts.size == 1:\n",
    "                df[c] = value_counts[0]\n",
    "            else:\n",
    "                df[c] = None\n",
    "    else:\n",
    "        df = grp.head(1)\n",
    "    return df\n",
    "\n",
    "all_data = all_data.groupby(\"id\").apply(merge).set_index(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_categorical(df, columns):\n",
    "    for col in columns:\n",
    "        df[col] = df[col].astype('category')\n",
    "convert_to_categorical(all_data,[\"heart_condition_detected_2017\",\"married\",\"high_BP\",\"job_status\",\n",
    "                                 \"sex\",\"smoker_status\",\"living_area\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(df):\n",
    "    return df[:ntrain], df[ntrain:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_train, preprocessed_test = split_train_test(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_by_mode(df,columns):\n",
    "    for col in columns:\n",
    "        df[col] = df[col].fillna(all_data[col].mode().iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_by_mode(all_data,[\"heart_condition_detected_2017\",\"high_BP\",\"married\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"sex\"] = all_data[\"sex\"].fillna(\"OTHER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Program\\Anaconda\\envs\\NLP\\lib\\site-packages\\pandas_profiling\\model\\correlations.py:124: UserWarning: There was an attempt to calculate the cramers correlation, but this failed.\n",
      "To hide this warning, disable the calculation\n",
      "(using `df.profile_report(correlations={\"cramers\": False}`)\n",
      "If this is problematic for your use case, please report this as an issue:\n",
      "https://github.com/pandas-profiling/pandas-profiling/issues\n",
      "(include the error message: 'The internally computed table of expected frequencies has a zero element at (0, 0).')\n",
      "  correlation_name=correlation_name, error=error\n"
     ]
    }
   ],
   "source": [
    "profile = all_data.profile_report(title='Medical Record Profiling Report')\n",
    "profile.to_file(output_file=\"train_data_summary.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
